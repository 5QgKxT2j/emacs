;;; Automatically generated on Tue Apr 22 13:16:30 2014
;;; Invoked by k-ohsugi@localhost using 24.3.1
(setq-default kill-ring '("% Created 2014-04-22 Tue 11:10
\\documentclass[dvipdfmx,11pt]{beamer}
\\usepackage{url}
\\usepackage{pxjahyper}
\\usetheme{Berlin}
\\setbeamertemplate{navigation symbols}{}
\\beamertemplatetextbibitems
\\setbeamertemplate{footline}[frame number]
\\setbeamertemplate{headline}{}


\\institute[]{大阪大学大学院情報科学研究科\\\\
            情報ネットワーク学専攻\\\\
            情報流通プラットフォーム講座 長谷川研究室 M2}
\\usetheme{default}
\\author{大杉 海斗}
\\date{\\today}
\\title{M2 Meeting}
\\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.3.1 (Org mode 8.2.5h)}}
\\begin{document}

\\maketitle

\\section{2014 年 4 月 22 日}
\\label{sec-1}
\\begin{frame}[label=sec-1-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-1-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item ディスパッチャの設計を擬似コードのレベルまで詳細化する
\\item 実験プランの作成
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-1-3]{進捗状況}
\\begin{itemize}
\\item パケット処理を行う CPU コアの数を増減させない擬似コードを作成した
\\item CPU コアを増減させる場合，増減が発生する条件と発生した時に必要な
処理を検討した
\\begin{itemize}
\\item いくつかの方法が考えられるので，本日のミーティングで決定したい
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-1-4]{擬似コードの設計概要}
\\begin{itemize}
\\item ディスパッチャとパケット処理はそれぞれスレッドで実装する
\\begin{itemize}
\\item prefix テーブルなどを共有するため
\\item Cisco は，それぞれがプロセスとして動作
\\end{itemize}
\\item 各スレッドは次のような設計になっている
\\begin{itemize}
\\item Dispatcher
\\begin{itemize}
\\item CPU0 で動作
\\item 常にパケットキューを監視
\\item packet\\_process が持つキューにパケットをエンキュー
\\end{itemize}
\\item packet\\_process
\\begin{itemize}
\\item CPU1 〜 3 で動作 (4 コアと仮定)
\\item 常に各 CPU が持つパケットキューを監視
\\item キューに入っているパケットを取り出し， process\\_input\\_*(CCNx に
よるパケット処理関数) にパケットを渡して実行
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-5]{CPU コアの省電力化}
\\begin{itemize}
\\item 使用していない CPU コアをシャットダウンすることで省電力化を行う
\\begin{itemize}
\\item /sys/devices/system/cpu/cpu 番号/online を 0 にすることでシャットダ
ウン可能
\\end{itemize}
\\item CPU コアをスリープして Idle にする方法もあるが，シャットダウンし
た場合の方が電力消費は少ない
\\item Linux kernel 2.6.18 以降は処理を少ない CPU コアに集める機能があるた
め OFF になっているか確認する (以下が 0)
\\begin{itemize}
\\item /sys/devices/system/cpu/sched\\_mc\\_power\\_savings
\\item /sys/devices/system/cpu/sched\\_smp\\_power\\_savings
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-6]{ディスパッチャが正しく動作していることを確認する実験プラン}
\\begin{itemize}
\\item root preifx が\"/a\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 ・ 2 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"・\"c\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:すべての CPU コアに負荷がかかる
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-7]{}
\\end{frame}

\\section{2014 年 4 月 15 日}
\\label{sec-2}
\\begin{frame}[label=sec-2-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-2-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 前回のミーティングで議論した事を踏まえて，ディスパッチャの現状の
設計をまとめる
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力を測定する
\\begin{itemize}
\\item パケットのサイズが 1.5KB 以下の時と 4KB の時を測定する
\\begin{itemize}
\\item 分割されたパケットの再構成に必要な CPU 負荷と消費電力も見たいため
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-3]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの現状の設計をまとめた
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力は測定できていない
\\item Intel と Broadcom の 10GbE カードについて調査した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-4]{10GbE カードでパケットを転送した時のスループット}
\\begin{itemize}
\\item 下記の通り，送信相手によってスループットに大きな差が出てしまい，そ
の原因が解明できなかったため，電力を測定する段階まで至らなかった
\\item スループットの測定には iperf を使用した
\\item TCP はクラアント-サーバだけ， UDP はルータ込でも測定したが結果に
影響はなかった
\\begin{itemize}
\\item Intel の 10GbE から Chelsio の 10GbE 
\\begin{itemize}
\\item TCP 9.5Gbps
\\item UDP 800Mbps
\\end{itemize}
\\item Chelsio の 10GbE から Intel の 10GbE
\\begin{itemize}
\\item TCP 3.0Gbps
\\item UDP 690Mbps
\\end{itemize}
\\item 両方のカードともに TCP offload は on ， UDP offload は off
\\begin{itemize}
\\item TCP が UDP よりも早いのは， offload の差だと思われる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-5]{10GbE カードでパケットを転送した時の CPU 負荷}
\\begin{itemize}
\\item TCP
\\begin{itemize}
\\item iperf でパケットの送受信をしたところ，クライアント・サーバ共に 30\\%程度は
CPU を使用していた
\\end{itemize}
\\item UDP
\\begin{itemize}
\\item クライアント・サーバ・ルータの CPU 負荷はどれも非常に小さい
\\begin{itemize}
\\item ルータで IP forwarding の役割をするプロセスは分からなかったが， CPU 負
荷の高いプロセスは見られなかった
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-6]{CPU 負荷に関する考察}
\\begin{itemize}
\\item CPU 使用率が， TCP での通信の時に UDP よりも大幅に大きくなる理由
\\begin{itemize}
\\item スループットが高いため，処理するパケットの数が多い
\\item UDP にない処理 (シーケンス番号の確認など) に必要なクロック数が
多い
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-7]{測定の際に気になった点}
\\begin{itemize}
\\item iperf のサーバ側では，パケット転送が終わった後も CPU 使用率が 200\\%
や 300\\%に張り付いたりする場合が見られた
\\begin{itemize}
\\item iperf の挙動が分からないため条件や理由などは不明である
\\begin{itemize}
\\item 今後の測定では， iperf 以外にも， CPU 使用率とスループットの両
方を測定可能な nuttcp を利用したいと考えている
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-8]{10GbE NIC の調査結果}
\\begin{itemize}
\\item 選定基準
\\begin{itemize}
\\item ルータ用に Dual Port
\\item 既存のケーブルが流用できる RJ-45 Copper か CX4 Copper
\\end{itemize}
\\item Intel
\\begin{itemize}
\\item Intel ® Ethernet Converged Network Adapter X540-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/58954/Intel-Ethernet-Converged-Network-Adapter-X540-T2}
\\end{itemize}
\\item Intel ® Ethernet Converged Network Adapter X520-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/69655/Intel-Ethernet-Converged-Network-Adapter-X520-T2}
\\end{itemize}
\\end{itemize}
\\item Broadcom (すべて 10GBASE-T Transceiver with XFI)
\\begin{itemize}
\\item BCM84846
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84846}
\\end{itemize}
\\item BCM84836
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84836}
\\end{itemize}
\\item BCM84833
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84833}
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-9]{}
\\begin{itemize}
\\item 次のスライド以降，現状のディスパッチャの設計をまとめる
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-10]{ディスパッチャの設計方針}
\\begin{itemize}
\\item 同一の Root Prefix を持つパケットが並列に処理されないようにする
\\begin{itemize}
\\item NPHT の排他制御が必要となるため
\\end{itemize}
\\item CS に関連するテーブルは，パーティショニングを行い，各 CPU に排他的
に割り当てする
\\begin{itemize}
\\item Data パケットの格納・削除が多く，複数の CPU コアで共有すると排他
制御が頻発し，パフォーマンスを大きく低下させることが予想されるた
め
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-11]{ディスパッチャのテーブル構造}
\\begin{itemize}
\\item 排他制御の頻度を考慮して，パーティショニングを行うテーブルとそう
でないものに分ける
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) はパーティショニングを行わない
\\item CSL (Content Skip List) ・ SHL (Straggler Hash Table) ・ CA
(Content Array) はパーティショニングを行う
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-12]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix ・それを処理する CPU ・その Root Prefix
を持つキャッシュパーティションの対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-13]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-14]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-15]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-16]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-17]{}
\\end{frame}
\\section{2014 年 4 月 9 日}
\\label{sec-3}
\\begin{frame}[label=sec-3-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-3-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) は，パーティショニングを行う必要が
ないと予想される
\\begin{itemize}
\\item 同じ Root Prefix を持つパケットが並列に処理されない
ようにすればよい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item パケット処理を CPU に割り当てするストラテジを考える必要がある
\\begin{itemize}
\\item CPU 使用率が 150\\%となるような処理を 3 つのコアに割り当てる時，
100\\%・ 50\\%・ 0\\%， 75\\%・ 75\\%・ 0\\%， 50\\%・ 50\\%・ 50\\%と割り当てる場合で
電力消費量が変化すると予想されるため
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-4]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの設計を行った
\\begin{itemize}
\\item 実際に C でコードを書き始めている
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-5]{懸念事項}
\\begin{itemize}
\\item NPHT はパーティショニングする必要がないが， CSL (Content Skip List)
や CA (Content Array) に関しては，パーティショニングする必要があ
ると思われる
\\begin{itemize}
\\item NPHT に比べてエントリの挿入と削除が頻発する
\\end{itemize}
\\item CSL と CA をパーティショニングして，各 CPU に割り当てする場合，以
下のディスパッチャの設計では CS の機能が活かせないため，再考する必
要がある
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-6]{}
\\centering
\\includegraphics[width=0.9\\linewidth,height=0.9\\textheight]{./figure/CCN_Algorithm_detail_CSL.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-7]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix とそれを処理する CPU の対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-8]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-9]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-10]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-11]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\item 研究の観点からも，負荷が増加するごとにコアの数を増やして行くほう
が推定しやすそう
\\item 方針が決まってからフローチャートを作成する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-12]{}
\\end{frame}
\\section{2014 年 4 月 1 日}
\\label{sec-4}
\\begin{frame}[label=sec-4-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item 下図の D (ディスパッチャ) と A0 〜 A2 (NDN パケットを処理するプロ
セス) がパケットを処理するのに要するクロック数を測定する
\\begin{itemize}
\\item 下図の A0 〜 A2 がパケットを処理するのに要するクロック数は，中井さんの測定し
た結果から分かる
\\item D が処理するのに要するクロック数は，新たに計測する
\\begin{itemize}
\\item そのために，まずはディスパッチャの設計を考える必要がある
\\end{itemize}
\\end{itemize}
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item フォワーディングエンジンの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item CCNx では， FIB と PIT を NPHT (Name Prefix Hash Table) で管理して
いるため， PIT と CS を排他的に割り当てするためには， NPHT ( FIB ・
PIT) と CS をパーティショニングする必要がある
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item Cisco は， PIT と CS を同一テーブルで管理し，それぞれの CPU コアへ
排他的に割り当て， FIB は CPU コア間で共有している
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-4]{進捗状況}
\\begin{itemize}
\\item 各 CPU コアにパケット処理を割り当てするディスパッチャを設計した
\\item ポスターの原稿を修正した
\\begin{itemize}
\\item CCN の説明を追加した
\\item 武政君の研究内容 (CCN ルータのキャッシュヒット率の導出) を追加した
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-5]{ディスパッチャの要件}
\\begin{itemize}
\\item できるだけ各 CPU の使用率を均等にする
\\item パケット処理は，そのパケットの親の処理が割り当てられたのと同じ
CPU に割り当てされなければならない
\\begin{itemize}
\\item FIB エントリの最長一致検索によるパケットフォワーディングのため，
各エントリは親エントリへのリンクを張っているから
\\item パケット /a/b/0 ・/a/b ・/a は，必ず同じ CPU に割り当てされる必要がある
\\end{itemize}
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item CPU コア間で FIB を共有しているため，パケットの full-name をハッ
シュ化し，そのハッシュ値で CPU コアへと振り分けしている
\\item full-name の偏りによっては，特定 CPU コアに処理が集中する可能性が
ある
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-6]{ディスパッチャの設計}
\\begin{itemize}
\\item 2 種類の設計を考えた
\\begin{itemize}
\\item 方式 1: 現在の各 CPU コアの負荷に関係なく，入力パケットの Root
Prefix\\footnote{Root Prefix: パケットの名前を tree に見立てた時の根に当たる Prefix (例: /a/b/0 ならば/a ，/b/c/d ならば/b)} のハッシュ値によってパケット処理を割り当てする CPU コアを
決定する
\\begin{itemize}
\\item (ハッシュ値 mod n) = 1 ならばコア 1 ， = 2 ならばコア 2\\ldots{}\\ldots{}の
ようなイメージ
\\item 処理が簡単
\\item 特定の CPU コアに負荷が集中する可能性がある
\\end{itemize}
\\item 方式 2: 現在の各 CPU コアの負荷に応じて，パケット処理を割り当て
する CPU コアを変更する
\\begin{itemize}
\\item 詳細は後述
\\item 処理が複雑
\\item 特定の CPU コアへの負荷の集中を防ぐことができる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-7]{方式 2 の詳細 (1)}
\\begin{itemize}
\\item パケットの処理をどの CPU コアへ割り当てするかの選択が，パケットの
Root Prefix にのみ依存することに着目
\\begin{itemize}
\\item Root Prefix と割り当てする CPU コアの対応をテーブルで管理する
\\begin{itemize}
\\item Root Prefix ならば，それほど数がなさそう
\\end{itemize}
\\end{itemize}
\\item Key は Root Prefix のハッシュ値
\\item テーブルにない Root Prefix を持つパケットが到着した時は， CPU 負荷
の低いコアへ割り当てし，その対応をテーブルに追加
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-8]{方式 2 の詳細 (2)}
\\begin{itemize}
\\item いつまでも同じコアへとパケットを割り当てをしていては，この方式の意
味がないため，一定時間 (Time to Live で指定) 経過後にテーブル
からエントリを削除
\\begin{itemize}
\\item Time to Live はその Root Prefix を持つすべてのパケットが対応する
FIB ・ PIT ・ CS の エントリが expire するまでの時間の最大値と同
じにする必要がある
\\begin{itemize}
\\item 該当するエントリがある FIB ・ PIT ・ CS を持つ App Process へとパ
ケットの処理を割り当てするため
\\end{itemize}
\\end{itemize}
\\item App Process はパケット処理後に Time to Live にセットする値を返す
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-9]{2 つの方式に対する考え}
\\begin{itemize}
\\item 方式 2 の方が現実的であると思われる
\\begin{itemize}
\\item 方式 1 では， 各 CPU コアの負荷がコンテンツの名前空間に依存する
\\begin{itemize}
\\item コンテンツの名前は，ルータのベンダが決められるものではないため，特定の CPU コアに処理が集中すると予想される
\\end{itemize}
\\end{itemize}
\\item 方式 2 の別案として，全 CPU コアに毎回 Root Prefix で lookup を行う方法もある
\\begin{itemize}
\\item テーブルを保持する必要はないが，オーバーヘッドが大きい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-10]{パケット (Interest/Data の両方) 到着時のプロセス}
\\begin{enumerate}
\\item パケットの Root Prefix より Hash 値を計算し，その値によりディス
パッチャの持つテーブルを参照
\\item HIT 時: ディスパッチャは， App Process へとパケット処理を割り当て
し， App Process から Time to Live にセットする値 (エントリの残り
時間) を受け取る
\\item MISS 時: CPU 使用率の低いコアへとパケット処理を割り当てし，テーブ
ルにエントリを作成 (Time to Live は App Process がパケット処理時
に返却)
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-4-11]{}
\\end{frame}

\\section{2014 年 3 月 25 日}
\\label{sec-5}
\\begin{frame}[label=sec-5-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電
力消費を測定するために必要なハードウェア・ソフトウェア構成を考え
る
\\begin{itemize}
\\item ハードウェアは，専用のルータではなく，一般的な PC を想定している
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-2]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-5-3]{進捗状況}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電力消
費を測定するために必要なハードウェア・ソフトウェア構成を考えた
\\item マルチコア CPU 環境におけるクロック数の測定方法を検討した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-4]{現在考えられる課題一覧}
\\begin{itemize}
\\item マルチスレッドに対応した NDN ソフトウェアの作成
\\begin{itemize}
\\item 特定 CPU コアへのスレッドの割り当て (おそらく下の API を用いることで可能)
\\begin{itemize}
\\item sched\\_get\\_affinity ()
\\item sched\\_set\\_affinity ()
\\item \\url{http:linuxjm.sourceforge.jp/html/LDP_man-pages/man2/sched_setaffinity.2.html}
\\end{itemize}
\\end{itemize}
\\item CPU がマルチコアの時に電力消費量を推定できるモデルの提案
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-5]{本日のミーティングで議論したいこと}
\\begin{itemize}
\\item NDN ルータのソフトウェア構成およびハードウェア構成に問題がないか
\\item 今後行っていく作業の優先順位付け
\\item 研究室紹介に使うポスターの内容
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-6]{NDN ルータのハードウェア構成}
\\begin{itemize}
\\item CPU: Intel Xeon E3-1220 (3.1GHz x 4 コア)
\\begin{itemize}
\\item ハイパースレッディングとターボブーストはとりあえず無効化する
\\end{itemize}
\\item Memory: DDR3 16GB,1600MHz
\\begin{itemize}
\\item FIB ・ PIT ・ CS のテーブルサイズについて今は考慮しないため，
Memory サイズはそれほど考慮しない
\\end{itemize}
\\item HDD: Western Digital 2TB SATA 3.5 inch \"WD2000FYYX\"
\\begin{itemize}
\\item Memory と同様であまり考慮しない
\\end{itemize}
\\item NIC: Intel 10-Gigabit Ethernet x 2
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-7]{NDN パケットフロー}
\\begin{itemize}
\\item 4 コアなので D と A0 〜 3 にそれぞれ 1 コアずつ割り当てる
\\end{itemize}
\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}
\\begin{frame}[label=sec-5-8]{NDN ルータのソフトウェア構成の概要}
\\begin{itemize}
\\item ソフトウェアの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item 一方で， PIT と CS に関しては，複数の CPU が同一エントリへアクセス
した時の排他制御によるパフォーマンスの低下が大きいと予想されるため，
PIT と CS はパーティショニングを行う
\\begin{itemize}
\\item マルチコアへのスレッドの割り当てなどは Cisco のデモを参考にする
\\end{itemize}
\\item ソフトウェアでは次のことを行う
\\begin{itemize}
\\item NDN パケットのフォワーディング処理
\\item CPU コアへのスレッドの割り当て (ディスパッチ処理)
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-9]{NDN ルータのソフトウェア}
\\begin{itemize}
\\item パケットの full-name のハッシュ値によって，パケットの処理を各 CPU コ
アに振り分ける
\\begin{itemize}
\\item NPHT (FIB ・ PIT) と CS を 3 つにパーティショニングする
\\begin{itemize}
\\item NPHT は， bucket が 6 つだとすると， 0 ・ 1 はテーブル 1 とし
てコア 1 ， 2 ・ 3 はテーブル 2 としてコア 2 ， 4 ・ 5 はテー
ブル 3 としてコア 3 というように割り当てする
\\item FIB までパーティショニングされてしまい， parent にリンクを貼
ることによる fast lookup が使えないという問題がある
\\end{itemize}
\\end{itemize}
\\item PIT (CS) の lookup 処理および insert 処理の前に，処理対象のパケッ
トの full-name をハッシュ化
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-10]{}
\\includegraphics[width=.9\\linewidth]{./figure/CCN_Algorithm_detail.pdf}
\\end{frame}

\\begin{frame}[label=sec-5-11]{Interest パケットがデーモンに到着した時のシーケンス}
\\begin{enumerate}
\\item パケットを name 部とオプション部に parse
\\item duplication check (重複検知)
\\item パケットの name 部からハッシュ値を計算， Prefix Seek の処理以降を
スレッドにし， ハッシュ値に応じた CPU コアに割り当て
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-5-12]{マルチコア CPU 環境におけるクロック数の測定方法}
\\begin{itemize}
\\item おそらく中井さんが用いた RDTSC 命令を用いることで，マルチコア CPU で
もクロック数の測定が可能である
\\begin{itemize}
\\item タイムスタンプカウンタ (TSC) が， Invariant TSC ならばマルチコ
ア環境でも正確にクロック数を測定可能である
\\begin{itemize}
\\item \\url{http:www.02.246.ne.jp/~torutk/cxx/clock/cpucounter.html}
\\end{itemize}
\\item 本実験で使う予定の Intel Xeon E3-1220 は Invariant TSC であることを確認した
\\end{itemize}
\\item さらに， Turbo boost でクロック数が変化した場合でも正確にクロック
を測定できる
\\item 一方で，マルチ CPU 環境ではクロック測定が困難であると予想される
\\begin{itemize}
\\item クロック数をリセットする信号がプロセッサ単位でしか送信できない
ため
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-5-13]{}
\\end{frame}

\\section{2014 年 3 月 17 日}
\\label{sec-6}
\\begin{frame}[label=sec-6-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えるかどうかを確認する
\\item 「 named data networking on a router forwarding at 20 gbps and
beyond 」を参考に， 20Gb や 40Gb の転送速度を出せるソフトウェアルー
タを作る時に，必要となるハードウェアの構成を考える
\\item CCNx のデータ構造とオペレーショナルフローについてまとめた資料の誤
りを修正する
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-2]{研究目標}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標 (5 月)}%x
\\begin{itemize}
\\item 現在，ルータのモデル化は， CPU がシングルコアの時のみできているた
め，モデルをマルチコア or マルチ CPU に対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-6-3]{目標達成に向けてのアプローチ}
\\begin{enumerate}
\\item 中井さんの資料および CCNx のソースコードを読み， CCNx ver8.1 の処理をブロッ
クに分割し，それぞれのブロックの処理に必要なクロック数を測定する
(最新 ver に拘らないならば，中井さんが実験を行った ver7.2 を使えばよ
 いため，このプロセスは飛ばすことができる)
\\item 1.で計測されたクロック数を基に， CCNx の挙動を模倣するプログラムを
作成する
\\begin{itemize}
\\item CCNx はマルチスレッドに対応していない (?) ため
\\item CCNx における各ブロックの処理にかかるクロック数だけ， dummy の処
理を行わせる
\\item NDN パケットの送受信するタイミングで， UDP パケットを送受信す
る
\\end{itemize}
\\item 2.で作成したプログラムを動作させた PC の電力消費を測定する
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-6-4]{進捗状況}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えることを確認した
\\begin{itemize}
\\item 他の PC とケーブルで繋ぎ， ping が通ることを確認
\\item 当該 PC の 10Gigabit-Ethernet カードを接続するスロット数 (PCI-Express x8)
は 1 つで，カードのインターフェース数は 2 つのため，最大で
20Gbps までしか測定できない
\\end{itemize}
\\item 「 named data networking on a router forwarding at
20 Gbps and beyond 」を読み必要なハードウェア構成について考えた
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-5]{議論したいこと}
\\begin{itemize}
\\item 今回ハードウェアの構成を考えたが， CCNx の動作で 20Gbps を達成するのは困難である
と予想された
\\item したがって，何にフォーカスを当て (コントリビューションは何か) ，
何を優先すべきかを議論したいと考えている
\\begin{itemize}
\\item 中井さんの提案したモデルを， CCNx の最新版に対応させること
\\item 中井さんの提案したモデルを，マルチコア or マルチ CPU に対応させること
\\item 現実的なアクセスルータを考慮して， 20Gbps や 40Gbps のスループットを達成できるハードウェアと，ソフ
トウェアを調査し，その電力消費量を測定すること
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-6]{}
\\begin{itemize}
\\item 次ページより，「 named data networking on a router forwarding at
20 Gbps and beyond 」の内容をまとめる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-7]{概要}
\\begin{itemize}
\\item Cisco ASR9000 上の Linux で NDN フォワーディングエンジンを動作さ
せ，そのパフォーマンスを測定している
\\item NDN フォワーディングエンジンは CCNx ではなく， CS ・ FIB ・ PIT のデータ構造も異なっ
ている
\\item シミュレーションの結果， Interest および Data のフォワーディング
スループットが， 20Gbps を超えることを示している
\\begin{itemize}
\\item シミュレーションでは，実際には NIC を通したパケットの送受信を行っておらず，
ファイルからパケットを読み込むことで擬似的なフォワーディング処理
を行っている
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-8]{Cisco の NDN ソフトウェアルータのハードウェア構成}
\\begin{itemize}
\\item モデル名: Cisco ASR9000
\\item CPU: Intel Xeon (Westmeie-EP) 2.0GHz 6 コア (Hyper-threading 有) * 2
\\item LAN: Intel Niantic 10Gigabit Ethernet  * 4
\\item Storage: 3.2TB SSD (NDN の Cache Storage として使用)
\\item 64bit Linux 上のソフトウェアでパケットフォワーディングを行ってい
る
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-9]{NDN フォワーディングエンジン}
\\begin{itemize}
\\item CCNx とはデータ構造や look up の方法が大きく異なる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-10]{FIB}
\\begin{itemize}
\\item FIB look up の方法が CCNx と異なる (あまり関係なさそうなので割愛)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-11]{CS ・ PIT}
\\begin{itemize}
\\item CS と PIT の管理は 1 つのハッシュテーブルで行い， look up は同時に
行う
\\begin{itemize}
\\item どちらも full-name を key とするため
\\item エントリが CS のものか PIT のものかは 1bit の flag で判断する
\\end{itemize}
\\item PIT (CS/PIT) を CPU の各コア (thread) に分割する
\\begin{itemize}
\\item 複数のコアで PIT を共有するとパフォーマンスが落ちるため
\\item Interest および Data の full-name のハッシュで PIT を CPU コア
(thread) に振り分け
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-12]{NDN パケットのフロー}
\\begin{itemize}
\\item App process (A0 〜 A7) で， NDN フォワーディング処理をすべて行う
(CS/PIT look up ， FIB look up)
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.6\\textheight]{./figure/NDN_packet_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-13]{シミュレーション結果}
\\begin{itemize}
\\item 16 個の IRCache URL のトレースから 1300 万 Interest を作成し，シミュレー
ションを行っている
\\item 異なる CPU コア上で動作させるスレッド数の増加に伴いパフォーマンスは向上している
\\item FIB と PIT のサイズはパフォーマンスにほとんど影響を与えていない
\\begin{itemize}
\\item PIT/CS サイズが向上するとパフォーマンスが低下していることから，
PIT/CS look up でほとんどヒットせず，エントリの探索に時間がかかっ
ただけになっているからではないかと思われる
\\end{itemize}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.4\\textheight]{./figure/performance_of_NDN.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-14]{20Gbps を達成する時に必要な CPU}
\\begin{itemize}
\\item 29.78G (clocks/s) を達成できるもの
\\begin{itemize}
\\item 1 秒間に処理するパケット数を算出 (パケットサイズ 2KB は， Interest と Data が同
数であると仮定し，標準チャンクサイズ 4KB を 2 で割って算出
(Interest のサイズは小さいので無視))
\\begin{itemize}
\\item 20Gbps / (2K*8) = 1.25M (packet/s)
\\end{itemize}
\\item Interest と Data のペアの処理にかかる合計クロック数 48787 をかけ
て 2 で割る (こちらも Interest と Data が同数であると仮定． CS
HIT0\\%のとき．中井さんの論文から算出)
\\begin{itemize}
\\item 1.25M * 48784 / 2  = 30491.88 M (clocks/s)
= 29.78 G (clocks/s)
\\end{itemize}
\\end{itemize}
\\item 上の計算仮定には， XML の処理が入っていない．また，パケットサイズ
を 2KB としているが， Cisco は 500B としている．したがって，上記の
結果は甘く見積もっており， CCNx の挙動をそのまま模倣すると CPU の処
理が間に合わないと予想される．
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-15]{20Gbps を達成する時に必要な主記憶}
\\begin{itemize}
\\item Cisco のデモから， FIB および PIT のサイズはあまりスループットに影響し
ていないため， 1Gbyte もあれば十分ではないかと思われる
\\item 一方で， FIB ・ PIT の fast look up は時間のかかる処理であるため，
主記憶の速度は重要である
\\begin{itemize}
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-16]{20Gbps を達成する時に必要なネットワークインターフェース}
\\begin{itemize}
\\item 10Gigabit-Ethernet * 4
\\begin{itemize}
\\item Cisco と同様
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-17]{}
\\end{frame}

\\section{2014 年 3 月 12 日}
\\label{sec-7}
\\begin{frame}[label=sec-7-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめたが，説明不足な部分があったた
め，コメントに基づいて更新を行なう
\\item 今後どのように研究を進めていくかを本日のミーティングで検討する
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-7-2]{進捗状況}
\\begin{itemize}
\\item 中井さんから，以下のことを引き継ぎしてもらった
\\begin{itemize}
\\item CCNx のソースコード中に RDTSC を埋め込んでクロック数を測定する方法
\\item 実験のネットワークへのアクセス方法と実験用スクリプトの使い方
\\end{itemize}
\\item 3/24 (月) に，実機を使って電力消費の測定を行なう (CCNx は，中井
さんが使っていたのと同じ ver7.1 を使用する)
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-3]{今後の予定 (仮)}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」と実
際のソースコードを読んだことで， CCNx の概要が分かってきたと思うた
め，ソースコードを読み進めつつ，ソースコード中のどこでクロックを
測定するべきか考えて行きたいと思っている
\\item 並行して， CCNx の理解を深めるため， CCNx1.0 へのロードマップを読み
進めていきたいと考えている (100 ページ程度あるため 2 〜 3 週間を目安に
考えている)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-4]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-5]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-6]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-7]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-8]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item ver8.1 では， SHT らしきものが見つけられなかった (重要ならばもう少し時間
をかけてソースコードを読みたいと思います)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-9]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\begin{itemize}
\\item 詳細は次ページ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-10]{CSL におけるコンテンツ名順の lookup}
\\begin{itemize}
\\item CSL では， Data がコンテンツの名前順に整列されている
\\item CSL での lookup のアルゴリズム挙動は次の通り
\\begin{enumerate}
\\item 右にポインタを辿り検索対象コンテンツ名とノードを比較する．
\\begin{itemize}
\\item コンテンツ名 $<$ ノード 再び 1 へ
\\item コンテツ名 $>$ ノード 元のノードへ戻り，階層を 1 つ下げて再び
1 へ，最下層なら 2 へ
\\item コンテンツ名 = ノード マッチしたので探索終了
\\end{itemize}
\\item 探索するコンテンツが存在しないので探索終了
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.9\\linewidth,height=0.5\\textheight]{./figure/cs_skiplist.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-11]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) のエントリ
Name Prefix Entry (NPE) によって管理される
\\begin{itemize}
\\item NPE は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\begin{block}{PEs}%x
\\begin{itemize}
\\item エントリ同士は，双方向でリンクされている
\\item メンバ変数
\\begin{itemize}
\\item 元の interest (unsigned int 型なので，おそらくバイナリのまま．
コメントによるとマッチングに使用する)
\\item 転送した interest のメッセージとそのサイズ
\\end{itemize}
\\end{itemize}
\\end{block}
\\begin{block}{FIEs}%x
\\begin{itemize}
\\item NPE 中に存在
\\item メンバ変数
\\begin{itemize}
\\item face の id
\\item expire までの残り時間
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-7-12]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\begin{itemize}
\\item Interest: process\\_incoming\\_interest
\\item Data: process\\_incoming\\_content
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-13]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-14]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の nameprefix が\\alert{すべて}存在するかを NPHT で
チェックする (Interest が/a/b/0/1 ならば，/a ・/a/b ・/a/b/0 ・
/a/b/0/1 をすべて)
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため挿入されたエントリは親 (1 コンポ
ネント短いエントリ) へのポインタを張る (Data が daemon に到
着した際に，できるだけ多くの Interest を消費するため． (3)
で詳細を述べる)
\\end{enumerate}
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-15]{Interest 処理のオペレーショナルフロー (2)}
\\begin{itemize}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\begin{itemize}
\\item コンポーネント数の比較
\\item Name 全体の長さの比較
\\item memcmp における Binary の Name 自体の比較
\\end{itemize}
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する Exclude や
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-16]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後，
Data を返送し， NPHT と PHT から Interest を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，/a/b/0/1 ・/a/b/0 ・/a/b ・/a を探索する
\\begin{itemize}
\\item オプションによっては， Interest の fullname と NPHT のエント
リが完全一致しなくても良い場合があるため
\\item Interest には， MinSuffixComponents と MaxSuffixComponents というオプ
ションが存在し，マッチしてほしいコンポーネントの範囲を指定することができる
\\item 例えば， Interest の fullname が/a/b/0/1 ， MaxSuffixComponents が
3 の時， Data /a/b/0/1 でも Interest の要件を満たしている
きる
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-7-17]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-18]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-19]{よく分からなかった点}
\\begin{itemize}
\\item CCNx のデータ構造の中に「 ccn\\_forwarding 」と「 ccn\\_forwarding\\_entry 」
の 2 つのデータ構造があった
\\item この 2 つのデータ構造は，互いに関係がない
\\item NPE からリンクが貼られていたのは前者
\\end{itemize}
\\end{frame}

\\section{2014 年 3 月 5 日}
\\label{sec-8}
\\begin{frame}[label=sec-8-1]{}
\\end{frame}
\\begin{frame}[label=sec-8-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめ， CCNx のデータ構造について
の理解を深める
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{長期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-8-3]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-4]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-5]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-6]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-7]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item どうやって Data が人気か判断するのか， CA と同じように accession
number でアクセスするのか分からないため，ソースを読む必要があ
る
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-8]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-9]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) によって管理
される
\\begin{itemize}
\\item NPHT は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-8-10]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-11]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-12]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の prefix が\\alert{すべて}存在するかを NPHT でチェックする
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため prefix は親へのポインタを張る
\\end{enumerate}
\\end{enumerate}
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-13]{Interest 処理のオペレーショナルフロー (2)}
\\begin{enumerate}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する除外フィルタなどがあ
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-8-14]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後， Data パケットを返送し， NPHT
と PHT から Interest の name を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，\\alert{/a/b/0 ・/a/b ・/a をすべて}探索
する
\\begin{itemize}
\\item できるだけ多くの Interest を消費するため
\\item 例えば， Interest /a/b/0 が，最初の 3 コンポネントでのみのマッチを
必要としている場合，コンテンツ/a/b/0/1 が Interest/a/b/0 を満たす
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-8-15]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-16]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-17]{所感}
\\begin{itemize}
\\item CCNx のデータ構造について大まかな理解はできたと思われる
\\item 一方で，各テーブルのエントリの構造などの細かい所については触れられ
ていなかったため，ソースコードを読んでいく必要があると感じた
\\end{itemize}
\\end{frame}
% Emacs 24.3.1 (Org mode 8.2.5h)
\\end{document}" #("   - 
" 0 3 (fontified t) 3 5 (fontified t) 5 6 (fontified t)) #("どのような" 0 5 (fontified t)) #("が必要" 0 3 (fontified t)) #("になるのか" 0 5 (fontified t)) #("か考えられていなかったので，" 0 13 (fontified t) 13 14 (fontified t)) #("パケットあるか" 0 7 (fontified t)) "% Created 2014-04-22 Tue 10:31
\\documentclass[dvipdfmx,11pt]{beamer}
\\usepackage{url}
\\usepackage{pxjahyper}
\\usetheme{Berlin}
\\setbeamertemplate{navigation symbols}{}
\\beamertemplatetextbibitems
\\setbeamertemplate{footline}[frame number]
\\setbeamertemplate{headline}{}


\\institute[]{大阪大学大学院情報科学研究科\\\\
            情報ネットワーク学専攻\\\\
            情報流通プラットフォーム講座 長谷川研究室 M2}
\\usetheme{default}
\\author{大杉 海斗}
\\date{\\today}
\\title{M2 Meeting}
\\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.3.1 (Org mode 8.2.5h)}}
\\begin{document}

\\maketitle

\\section{2014 年 4 月 22 日}
\\label{sec-1}
\\begin{frame}[label=sec-1-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-1-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item ディスパッチャの設計を擬似コードのレベルまで詳細化する
\\item 実験プランの作成
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-3]{擬似コードの設計概要}
\\begin{itemize}
\\item ディスパッチャとパケット処理はそれぞれスレッドで実装する
\\begin{itemize}
\\item prefix テーブルなどを共有するため
\\item Cisco は，それぞれがプロセスとして動作
\\end{itemize}
\\item 各スレッドは次のような設計になっている
\\begin{itemize}
\\item Dispatcher
\\begin{itemize}
\\item CPU0 で動作
\\item 常にパケットキューを監視
\\item packet\\_process が持つキューにパケットをエンキュー
\\end{itemize}
\\item packet\\_process
\\begin{itemize}
\\item CPU1 〜 3 で動作 (4 コアと仮定)
\\item 常に各 CPU が持つパケットキューを監視
\\item キューに入っているパケットを取り出し， process\\_input\\_*(CCNx に
よるパケット処理関数) にパケットを渡して実行
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-4]{CPU コアの省電力化}
\\begin{itemize}
\\item 使用していない CPU コアをシャットダウンすることで省電力化を行う
\\begin{itemize}
\\item /sys/devices/system/cpu/cpu 番号/online を 0 にすることでシャットダ
ウン可能
\\end{itemize}
\\item CPU コアをスリープして Idle にする方法もあるが，シャットダウンし
た場合の方が電力消費は少ない
\\item Linux kernel 2.6.18 以降は処理を少ない CPU コアに集める機能があるた
め OFF になっているか確認する (以下が 0)
\\begin{itemize}
\\item /sys/devices/system/cpu/sched\\_mc\\_power\\_savings
\\item /sys/devices/system/cpu/sched\\_smp\\_power\\_savings
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-5]{ディスパッチャが正しく動作していることを確認する実験プラン}
\\begin{itemize}
\\item root preifx が\"/a\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 ・ 2 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"・\"c\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:すべての CPU コアに負荷がかかる
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-6]{}
\\end{frame}

\\section{2014 年 4 月 15 日}
\\label{sec-2}
\\begin{frame}[label=sec-2-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-2-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 前回のミーティングで議論した事を踏まえて，ディスパッチャの現状の
設計をまとめる
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力を測定する
\\begin{itemize}
\\item パケットのサイズが 1.5KB 以下の時と 4KB の時を測定する
\\begin{itemize}
\\item 分割されたパケットの再構成に必要な CPU 負荷と消費電力も見たいため
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-3]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの現状の設計をまとめた
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力は測定できていない
\\item Intel と Broadcom の 10GbE カードについて調査した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-4]{10GbE カードでパケットを転送した時のスループット}
\\begin{itemize}
\\item 下記の通り，送信相手によってスループットに大きな差が出てしまい，そ
の原因が解明できなかったため，電力を測定する段階まで至らなかった
\\item スループットの測定には iperf を使用した
\\item TCP はクラアント-サーバだけ， UDP はルータ込でも測定したが結果に
影響はなかった
\\begin{itemize}
\\item Intel の 10GbE から Chelsio の 10GbE 
\\begin{itemize}
\\item TCP 9.5Gbps
\\item UDP 800Mbps
\\end{itemize}
\\item Chelsio の 10GbE から Intel の 10GbE
\\begin{itemize}
\\item TCP 3.0Gbps
\\item UDP 690Mbps
\\end{itemize}
\\item 両方のカードともに TCP offload は on ， UDP offload は off
\\begin{itemize}
\\item TCP が UDP よりも早いのは， offload の差だと思われる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-5]{10GbE カードでパケットを転送した時の CPU 負荷}
\\begin{itemize}
\\item TCP
\\begin{itemize}
\\item iperf でパケットの送受信をしたところ，クライアント・サーバ共に 30\\%程度は
CPU を使用していた
\\end{itemize}
\\item UDP
\\begin{itemize}
\\item クライアント・サーバ・ルータの CPU 負荷はどれも非常に小さい
\\begin{itemize}
\\item ルータで IP forwarding の役割をするプロセスは分からなかったが， CPU 負
荷の高いプロセスは見られなかった
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-6]{CPU 負荷に関する考察}
\\begin{itemize}
\\item CPU 使用率が， TCP での通信の時に UDP よりも大幅に大きくなる理由
\\begin{itemize}
\\item スループットが高いため，処理するパケットの数が多い
\\item UDP にない処理 (シーケンス番号の確認など) に必要なクロック数が
多い
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-7]{測定の際に気になった点}
\\begin{itemize}
\\item iperf のサーバ側では，パケット転送が終わった後も CPU 使用率が 200\\%
や 300\\%に張り付いたりする場合が見られた
\\begin{itemize}
\\item iperf の挙動が分からないため条件や理由などは不明である
\\begin{itemize}
\\item 今後の測定では， iperf 以外にも， CPU 使用率とスループットの両
方を測定可能な nuttcp を利用したいと考えている
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-8]{10GbE NIC の調査結果}
\\begin{itemize}
\\item 選定基準
\\begin{itemize}
\\item ルータ用に Dual Port
\\item 既存のケーブルが流用できる RJ-45 Copper か CX4 Copper
\\end{itemize}
\\item Intel
\\begin{itemize}
\\item Intel ® Ethernet Converged Network Adapter X540-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/58954/Intel-Ethernet-Converged-Network-Adapter-X540-T2}
\\end{itemize}
\\item Intel ® Ethernet Converged Network Adapter X520-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/69655/Intel-Ethernet-Converged-Network-Adapter-X520-T2}
\\end{itemize}
\\end{itemize}
\\item Broadcom (すべて 10GBASE-T Transceiver with XFI)
\\begin{itemize}
\\item BCM84846
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84846}
\\end{itemize}
\\item BCM84836
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84836}
\\end{itemize}
\\item BCM84833
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84833}
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-9]{}
\\begin{itemize}
\\item 次のスライド以降，現状のディスパッチャの設計をまとめる
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-10]{ディスパッチャの設計方針}
\\begin{itemize}
\\item 同一の Root Prefix を持つパケットが並列に処理されないようにする
\\begin{itemize}
\\item NPHT の排他制御が必要となるため
\\end{itemize}
\\item CS に関連するテーブルは，パーティショニングを行い，各 CPU に排他的
に割り当てする
\\begin{itemize}
\\item Data パケットの格納・削除が多く，複数の CPU コアで共有すると排他
制御が頻発し，パフォーマンスを大きく低下させることが予想されるた
め
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-11]{ディスパッチャのテーブル構造}
\\begin{itemize}
\\item 排他制御の頻度を考慮して，パーティショニングを行うテーブルとそう
でないものに分ける
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) はパーティショニングを行わない
\\item CSL (Content Skip List) ・ SHL (Straggler Hash Table) ・ CA
(Content Array) はパーティショニングを行う
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-12]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix ・それを処理する CPU ・その Root Prefix
を持つキャッシュパーティションの対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-13]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-14]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-15]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-16]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-17]{}
\\end{frame}
\\section{2014 年 4 月 9 日}
\\label{sec-3}
\\begin{frame}[label=sec-3-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-3-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) は，パーティショニングを行う必要が
ないと予想される
\\begin{itemize}
\\item 同じ Root Prefix を持つパケットが並列に処理されない
ようにすればよい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item パケット処理を CPU に割り当てするストラテジを考える必要がある
\\begin{itemize}
\\item CPU 使用率が 150\\%となるような処理を 3 つのコアに割り当てる時，
100\\%・ 50\\%・ 0\\%， 75\\%・ 75\\%・ 0\\%， 50\\%・ 50\\%・ 50\\%と割り当てる場合で
電力消費量が変化すると予想されるため
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-4]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの設計を行った
\\begin{itemize}
\\item 実際に C でコードを書き始めている
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-5]{懸念事項}
\\begin{itemize}
\\item NPHT はパーティショニングする必要がないが， CSL (Content Skip List)
や CA (Content Array) に関しては，パーティショニングする必要があ
ると思われる
\\begin{itemize}
\\item NPHT に比べてエントリの挿入と削除が頻発する
\\end{itemize}
\\item CSL と CA をパーティショニングして，各 CPU に割り当てする場合，以
下のディスパッチャの設計では CS の機能が活かせないため，再考する必
要がある
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-6]{}
\\centering
\\includegraphics[width=0.9\\linewidth,height=0.9\\textheight]{./figure/CCN_Algorithm_detail_CSL.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-7]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix とそれを処理する CPU の対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-8]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-9]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-10]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-11]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\item 研究の観点からも，負荷が増加するごとにコアの数を増やして行くほう
が推定しやすそう
\\item 方針が決まってからフローチャートを作成する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-12]{}
\\end{frame}
\\section{2014 年 4 月 1 日}
\\label{sec-4}
\\begin{frame}[label=sec-4-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item 下図の D (ディスパッチャ) と A0 〜 A2 (NDN パケットを処理するプロ
セス) がパケットを処理するのに要するクロック数を測定する
\\begin{itemize}
\\item 下図の A0 〜 A2 がパケットを処理するのに要するクロック数は，中井さんの測定し
た結果から分かる
\\item D が処理するのに要するクロック数は，新たに計測する
\\begin{itemize}
\\item そのために，まずはディスパッチャの設計を考える必要がある
\\end{itemize}
\\end{itemize}
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item フォワーディングエンジンの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item CCNx では， FIB と PIT を NPHT (Name Prefix Hash Table) で管理して
いるため， PIT と CS を排他的に割り当てするためには， NPHT ( FIB ・
PIT) と CS をパーティショニングする必要がある
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item Cisco は， PIT と CS を同一テーブルで管理し，それぞれの CPU コアへ
排他的に割り当て， FIB は CPU コア間で共有している
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-4]{進捗状況}
\\begin{itemize}
\\item 各 CPU コアにパケット処理を割り当てするディスパッチャを設計した
\\item ポスターの原稿を修正した
\\begin{itemize}
\\item CCN の説明を追加した
\\item 武政君の研究内容 (CCN ルータのキャッシュヒット率の導出) を追加した
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-5]{ディスパッチャの要件}
\\begin{itemize}
\\item できるだけ各 CPU の使用率を均等にする
\\item パケット処理は，そのパケットの親の処理が割り当てられたのと同じ
CPU に割り当てされなければならない
\\begin{itemize}
\\item FIB エントリの最長一致検索によるパケットフォワーディングのため，
各エントリは親エントリへのリンクを張っているから
\\item パケット /a/b/0 ・/a/b ・/a は，必ず同じ CPU に割り当てされる必要がある
\\end{itemize}
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item CPU コア間で FIB を共有しているため，パケットの full-name をハッ
シュ化し，そのハッシュ値で CPU コアへと振り分けしている
\\item full-name の偏りによっては，特定 CPU コアに処理が集中する可能性が
ある
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-6]{ディスパッチャの設計}
\\begin{itemize}
\\item 2 種類の設計を考えた
\\begin{itemize}
\\item 方式 1: 現在の各 CPU コアの負荷に関係なく，入力パケットの Root
Prefix\\footnote{Root Prefix: パケットの名前を tree に見立てた時の根に当たる Prefix (例: /a/b/0 ならば/a ，/b/c/d ならば/b)} のハッシュ値によってパケット処理を割り当てする CPU コアを
決定する
\\begin{itemize}
\\item (ハッシュ値 mod n) = 1 ならばコア 1 ， = 2 ならばコア 2\\ldots{}\\ldots{}の
ようなイメージ
\\item 処理が簡単
\\item 特定の CPU コアに負荷が集中する可能性がある
\\end{itemize}
\\item 方式 2: 現在の各 CPU コアの負荷に応じて，パケット処理を割り当て
する CPU コアを変更する
\\begin{itemize}
\\item 詳細は後述
\\item 処理が複雑
\\item 特定の CPU コアへの負荷の集中を防ぐことができる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-7]{方式 2 の詳細 (1)}
\\begin{itemize}
\\item パケットの処理をどの CPU コアへ割り当てするかの選択が，パケットの
Root Prefix にのみ依存することに着目
\\begin{itemize}
\\item Root Prefix と割り当てする CPU コアの対応をテーブルで管理する
\\begin{itemize}
\\item Root Prefix ならば，それほど数がなさそう
\\end{itemize}
\\end{itemize}
\\item Key は Root Prefix のハッシュ値
\\item テーブルにない Root Prefix を持つパケットが到着した時は， CPU 負荷
の低いコアへ割り当てし，その対応をテーブルに追加
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-8]{方式 2 の詳細 (2)}
\\begin{itemize}
\\item いつまでも同じコアへとパケットを割り当てをしていては，この方式の意
味がないため，一定時間 (Time to Live で指定) 経過後にテーブル
からエントリを削除
\\begin{itemize}
\\item Time to Live はその Root Prefix を持つすべてのパケットが対応する
FIB ・ PIT ・ CS の エントリが expire するまでの時間の最大値と同
じにする必要がある
\\begin{itemize}
\\item 該当するエントリがある FIB ・ PIT ・ CS を持つ App Process へとパ
ケットの処理を割り当てするため
\\end{itemize}
\\end{itemize}
\\item App Process はパケット処理後に Time to Live にセットする値を返す
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-9]{2 つの方式に対する考え}
\\begin{itemize}
\\item 方式 2 の方が現実的であると思われる
\\begin{itemize}
\\item 方式 1 では， 各 CPU コアの負荷がコンテンツの名前空間に依存する
\\begin{itemize}
\\item コンテンツの名前は，ルータのベンダが決められるものではないため，特定の CPU コアに処理が集中すると予想される
\\end{itemize}
\\end{itemize}
\\item 方式 2 の別案として，全 CPU コアに毎回 Root Prefix で lookup を行う方法もある
\\begin{itemize}
\\item テーブルを保持する必要はないが，オーバーヘッドが大きい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-10]{パケット (Interest/Data の両方) 到着時のプロセス}
\\begin{enumerate}
\\item パケットの Root Prefix より Hash 値を計算し，その値によりディス
パッチャの持つテーブルを参照
\\item HIT 時: ディスパッチャは， App Process へとパケット処理を割り当て
し， App Process から Time to Live にセットする値 (エントリの残り
時間) を受け取る
\\item MISS 時: CPU 使用率の低いコアへとパケット処理を割り当てし，テーブ
ルにエントリを作成 (Time to Live は App Process がパケット処理時
に返却)
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-4-11]{}
\\end{frame}

\\section{2014 年 3 月 25 日}
\\label{sec-5}
\\begin{frame}[label=sec-5-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電
力消費を測定するために必要なハードウェア・ソフトウェア構成を考え
る
\\begin{itemize}
\\item ハードウェアは，専用のルータではなく，一般的な PC を想定している
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-2]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-5-3]{進捗状況}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電力消
費を測定するために必要なハードウェア・ソフトウェア構成を考えた
\\item マルチコア CPU 環境におけるクロック数の測定方法を検討した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-4]{現在考えられる課題一覧}
\\begin{itemize}
\\item マルチスレッドに対応した NDN ソフトウェアの作成
\\begin{itemize}
\\item 特定 CPU コアへのスレッドの割り当て (おそらく下の API を用いることで可能)
\\begin{itemize}
\\item sched\\_get\\_affinity ()
\\item sched\\_set\\_affinity ()
\\item \\url{http:linuxjm.sourceforge.jp/html/LDP_man-pages/man2/sched_setaffinity.2.html}
\\end{itemize}
\\end{itemize}
\\item CPU がマルチコアの時に電力消費量を推定できるモデルの提案
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-5]{本日のミーティングで議論したいこと}
\\begin{itemize}
\\item NDN ルータのソフトウェア構成およびハードウェア構成に問題がないか
\\item 今後行っていく作業の優先順位付け
\\item 研究室紹介に使うポスターの内容
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-6]{NDN ルータのハードウェア構成}
\\begin{itemize}
\\item CPU: Intel Xeon E3-1220 (3.1GHz x 4 コア)
\\begin{itemize}
\\item ハイパースレッディングとターボブーストはとりあえず無効化する
\\end{itemize}
\\item Memory: DDR3 16GB,1600MHz
\\begin{itemize}
\\item FIB ・ PIT ・ CS のテーブルサイズについて今は考慮しないため，
Memory サイズはそれほど考慮しない
\\end{itemize}
\\item HDD: Western Digital 2TB SATA 3.5 inch \"WD2000FYYX\"
\\begin{itemize}
\\item Memory と同様であまり考慮しない
\\end{itemize}
\\item NIC: Intel 10-Gigabit Ethernet x 2
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-7]{NDN パケットフロー}
\\begin{itemize}
\\item 4 コアなので D と A0 〜 3 にそれぞれ 1 コアずつ割り当てる
\\end{itemize}
\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}
\\begin{frame}[label=sec-5-8]{NDN ルータのソフトウェア構成の概要}
\\begin{itemize}
\\item ソフトウェアの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item 一方で， PIT と CS に関しては，複数の CPU が同一エントリへアクセス
した時の排他制御によるパフォーマンスの低下が大きいと予想されるため，
PIT と CS はパーティショニングを行う
\\begin{itemize}
\\item マルチコアへのスレッドの割り当てなどは Cisco のデモを参考にする
\\end{itemize}
\\item ソフトウェアでは次のことを行う
\\begin{itemize}
\\item NDN パケットのフォワーディング処理
\\item CPU コアへのスレッドの割り当て (ディスパッチ処理)
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-9]{NDN ルータのソフトウェア}
\\begin{itemize}
\\item パケットの full-name のハッシュ値によって，パケットの処理を各 CPU コ
アに振り分ける
\\begin{itemize}
\\item NPHT (FIB ・ PIT) と CS を 3 つにパーティショニングする
\\begin{itemize}
\\item NPHT は， bucket が 6 つだとすると， 0 ・ 1 はテーブル 1 とし
てコア 1 ， 2 ・ 3 はテーブル 2 としてコア 2 ， 4 ・ 5 はテー
ブル 3 としてコア 3 というように割り当てする
\\item FIB までパーティショニングされてしまい， parent にリンクを貼
ることによる fast lookup が使えないという問題がある
\\end{itemize}
\\end{itemize}
\\item PIT (CS) の lookup 処理および insert 処理の前に，処理対象のパケッ
トの full-name をハッシュ化
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-10]{}
\\includegraphics[width=.9\\linewidth]{./figure/CCN_Algorithm_detail.pdf}
\\end{frame}

\\begin{frame}[label=sec-5-11]{Interest パケットがデーモンに到着した時のシーケンス}
\\begin{enumerate}
\\item パケットを name 部とオプション部に parse
\\item duplication check (重複検知)
\\item パケットの name 部からハッシュ値を計算， Prefix Seek の処理以降を
スレッドにし， ハッシュ値に応じた CPU コアに割り当て
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-5-12]{マルチコア CPU 環境におけるクロック数の測定方法}
\\begin{itemize}
\\item おそらく中井さんが用いた RDTSC 命令を用いることで，マルチコア CPU で
もクロック数の測定が可能である
\\begin{itemize}
\\item タイムスタンプカウンタ (TSC) が， Invariant TSC ならばマルチコ
ア環境でも正確にクロック数を測定可能である
\\begin{itemize}
\\item \\url{http:www.02.246.ne.jp/~torutk/cxx/clock/cpucounter.html}
\\end{itemize}
\\item 本実験で使う予定の Intel Xeon E3-1220 は Invariant TSC であることを確認した
\\end{itemize}
\\item さらに， Turbo boost でクロック数が変化した場合でも正確にクロック
を測定できる
\\item 一方で，マルチ CPU 環境ではクロック測定が困難であると予想される
\\begin{itemize}
\\item クロック数をリセットする信号がプロセッサ単位でしか送信できない
ため
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-5-13]{}
\\end{frame}

\\section{2014 年 3 月 17 日}
\\label{sec-6}
\\begin{frame}[label=sec-6-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えるかどうかを確認する
\\item 「 named data networking on a router forwarding at 20 gbps and
beyond 」を参考に， 20Gb や 40Gb の転送速度を出せるソフトウェアルー
タを作る時に，必要となるハードウェアの構成を考える
\\item CCNx のデータ構造とオペレーショナルフローについてまとめた資料の誤
りを修正する
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-2]{研究目標}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標 (5 月)}%x
\\begin{itemize}
\\item 現在，ルータのモデル化は， CPU がシングルコアの時のみできているた
め，モデルをマルチコア or マルチ CPU に対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-6-3]{目標達成に向けてのアプローチ}
\\begin{enumerate}
\\item 中井さんの資料および CCNx のソースコードを読み， CCNx ver8.1 の処理をブロッ
クに分割し，それぞれのブロックの処理に必要なクロック数を測定する
(最新 ver に拘らないならば，中井さんが実験を行った ver7.2 を使えばよ
 いため，このプロセスは飛ばすことができる)
\\item 1.で計測されたクロック数を基に， CCNx の挙動を模倣するプログラムを
作成する
\\begin{itemize}
\\item CCNx はマルチスレッドに対応していない (?) ため
\\item CCNx における各ブロックの処理にかかるクロック数だけ， dummy の処
理を行わせる
\\item NDN パケットの送受信するタイミングで， UDP パケットを送受信す
る
\\end{itemize}
\\item 2.で作成したプログラムを動作させた PC の電力消費を測定する
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-6-4]{進捗状況}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えることを確認した
\\begin{itemize}
\\item 他の PC とケーブルで繋ぎ， ping が通ることを確認
\\item 当該 PC の 10Gigabit-Ethernet カードを接続するスロット数 (PCI-Express x8)
は 1 つで，カードのインターフェース数は 2 つのため，最大で
20Gbps までしか測定できない
\\end{itemize}
\\item 「 named data networking on a router forwarding at
20 Gbps and beyond 」を読み必要なハードウェア構成について考えた
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-5]{議論したいこと}
\\begin{itemize}
\\item 今回ハードウェアの構成を考えたが， CCNx の動作で 20Gbps を達成するのは困難である
と予想された
\\item したがって，何にフォーカスを当て (コントリビューションは何か) ，
何を優先すべきかを議論したいと考えている
\\begin{itemize}
\\item 中井さんの提案したモデルを， CCNx の最新版に対応させること
\\item 中井さんの提案したモデルを，マルチコア or マルチ CPU に対応させること
\\item 現実的なアクセスルータを考慮して， 20Gbps や 40Gbps のスループットを達成できるハードウェアと，ソフ
トウェアを調査し，その電力消費量を測定すること
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-6]{}
\\begin{itemize}
\\item 次ページより，「 named data networking on a router forwarding at
20 Gbps and beyond 」の内容をまとめる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-7]{概要}
\\begin{itemize}
\\item Cisco ASR9000 上の Linux で NDN フォワーディングエンジンを動作さ
せ，そのパフォーマンスを測定している
\\item NDN フォワーディングエンジンは CCNx ではなく， CS ・ FIB ・ PIT のデータ構造も異なっ
ている
\\item シミュレーションの結果， Interest および Data のフォワーディング
スループットが， 20Gbps を超えることを示している
\\begin{itemize}
\\item シミュレーションでは，実際には NIC を通したパケットの送受信を行っておらず，
ファイルからパケットを読み込むことで擬似的なフォワーディング処理
を行っている
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-8]{Cisco の NDN ソフトウェアルータのハードウェア構成}
\\begin{itemize}
\\item モデル名: Cisco ASR9000
\\item CPU: Intel Xeon (Westmeie-EP) 2.0GHz 6 コア (Hyper-threading 有) * 2
\\item LAN: Intel Niantic 10Gigabit Ethernet  * 4
\\item Storage: 3.2TB SSD (NDN の Cache Storage として使用)
\\item 64bit Linux 上のソフトウェアでパケットフォワーディングを行ってい
る
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-9]{NDN フォワーディングエンジン}
\\begin{itemize}
\\item CCNx とはデータ構造や look up の方法が大きく異なる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-10]{FIB}
\\begin{itemize}
\\item FIB look up の方法が CCNx と異なる (あまり関係なさそうなので割愛)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-11]{CS ・ PIT}
\\begin{itemize}
\\item CS と PIT の管理は 1 つのハッシュテーブルで行い， look up は同時に
行う
\\begin{itemize}
\\item どちらも full-name を key とするため
\\item エントリが CS のものか PIT のものかは 1bit の flag で判断する
\\end{itemize}
\\item PIT (CS/PIT) を CPU の各コア (thread) に分割する
\\begin{itemize}
\\item 複数のコアで PIT を共有するとパフォーマンスが落ちるため
\\item Interest および Data の full-name のハッシュで PIT を CPU コア
(thread) に振り分け
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-12]{NDN パケットのフロー}
\\begin{itemize}
\\item App process (A0 〜 A7) で， NDN フォワーディング処理をすべて行う
(CS/PIT look up ， FIB look up)
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.6\\textheight]{./figure/NDN_packet_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-13]{シミュレーション結果}
\\begin{itemize}
\\item 16 個の IRCache URL のトレースから 1300 万 Interest を作成し，シミュレー
ションを行っている
\\item 異なる CPU コア上で動作させるスレッド数の増加に伴いパフォーマンスは向上している
\\item FIB と PIT のサイズはパフォーマンスにほとんど影響を与えていない
\\begin{itemize}
\\item PIT/CS サイズが向上するとパフォーマンスが低下していることから，
PIT/CS look up でほとんどヒットせず，エントリの探索に時間がかかっ
ただけになっているからではないかと思われる
\\end{itemize}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.4\\textheight]{./figure/performance_of_NDN.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-14]{20Gbps を達成する時に必要な CPU}
\\begin{itemize}
\\item 29.78G (clocks/s) を達成できるもの
\\begin{itemize}
\\item 1 秒間に処理するパケット数を算出 (パケットサイズ 2KB は， Interest と Data が同
数であると仮定し，標準チャンクサイズ 4KB を 2 で割って算出
(Interest のサイズは小さいので無視))
\\begin{itemize}
\\item 20Gbps / (2K*8) = 1.25M (packet/s)
\\end{itemize}
\\item Interest と Data のペアの処理にかかる合計クロック数 48787 をかけ
て 2 で割る (こちらも Interest と Data が同数であると仮定． CS
HIT0\\%のとき．中井さんの論文から算出)
\\begin{itemize}
\\item 1.25M * 48784 / 2  = 30491.88 M (clocks/s)
= 29.78 G (clocks/s)
\\end{itemize}
\\end{itemize}
\\item 上の計算仮定には， XML の処理が入っていない．また，パケットサイズ
を 2KB としているが， Cisco は 500B としている．したがって，上記の
結果は甘く見積もっており， CCNx の挙動をそのまま模倣すると CPU の処
理が間に合わないと予想される．
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-15]{20Gbps を達成する時に必要な主記憶}
\\begin{itemize}
\\item Cisco のデモから， FIB および PIT のサイズはあまりスループットに影響し
ていないため， 1Gbyte もあれば十分ではないかと思われる
\\item 一方で， FIB ・ PIT の fast look up は時間のかかる処理であるため，
主記憶の速度は重要である
\\begin{itemize}
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-16]{20Gbps を達成する時に必要なネットワークインターフェース}
\\begin{itemize}
\\item 10Gigabit-Ethernet * 4
\\begin{itemize}
\\item Cisco と同様
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-17]{}
\\end{frame}

\\section{2014 年 3 月 12 日}
\\label{sec-7}
\\begin{frame}[label=sec-7-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめたが，説明不足な部分があったた
め，コメントに基づいて更新を行なう
\\item 今後どのように研究を進めていくかを本日のミーティングで検討する
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-7-2]{進捗状況}
\\begin{itemize}
\\item 中井さんから，以下のことを引き継ぎしてもらった
\\begin{itemize}
\\item CCNx のソースコード中に RDTSC を埋め込んでクロック数を測定する方法
\\item 実験のネットワークへのアクセス方法と実験用スクリプトの使い方
\\end{itemize}
\\item 3/24 (月) に，実機を使って電力消費の測定を行なう (CCNx は，中井
さんが使っていたのと同じ ver7.1 を使用する)
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-3]{今後の予定 (仮)}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」と実
際のソースコードを読んだことで， CCNx の概要が分かってきたと思うた
め，ソースコードを読み進めつつ，ソースコード中のどこでクロックを
測定するべきか考えて行きたいと思っている
\\item 並行して， CCNx の理解を深めるため， CCNx1.0 へのロードマップを読み
進めていきたいと考えている (100 ページ程度あるため 2 〜 3 週間を目安に
考えている)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-4]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-5]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-6]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-7]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-8]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item ver8.1 では， SHT らしきものが見つけられなかった (重要ならばもう少し時間
をかけてソースコードを読みたいと思います)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-9]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\begin{itemize}
\\item 詳細は次ページ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-10]{CSL におけるコンテンツ名順の lookup}
\\begin{itemize}
\\item CSL では， Data がコンテンツの名前順に整列されている
\\item CSL での lookup のアルゴリズム挙動は次の通り
\\begin{enumerate}
\\item 右にポインタを辿り検索対象コンテンツ名とノードを比較する．
\\begin{itemize}
\\item コンテンツ名 $<$ ノード 再び 1 へ
\\item コンテツ名 $>$ ノード 元のノードへ戻り，階層を 1 つ下げて再び
1 へ，最下層なら 2 へ
\\item コンテンツ名 = ノード マッチしたので探索終了
\\end{itemize}
\\item 探索するコンテンツが存在しないので探索終了
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.9\\linewidth,height=0.5\\textheight]{./figure/cs_skiplist.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-11]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) のエントリ
Name Prefix Entry (NPE) によって管理される
\\begin{itemize}
\\item NPE は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\begin{block}{PEs}%x
\\begin{itemize}
\\item エントリ同士は，双方向でリンクされている
\\item メンバ変数
\\begin{itemize}
\\item 元の interest (unsigned int 型なので，おそらくバイナリのまま．
コメントによるとマッチングに使用する)
\\item 転送した interest のメッセージとそのサイズ
\\end{itemize}
\\end{itemize}
\\end{block}
\\begin{block}{FIEs}%x
\\begin{itemize}
\\item NPE 中に存在
\\item メンバ変数
\\begin{itemize}
\\item face の id
\\item expire までの残り時間
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-7-12]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\begin{itemize}
\\item Interest: process\\_incoming\\_interest
\\item Data: process\\_incoming\\_content
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-13]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-14]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の nameprefix が\\alert{すべて}存在するかを NPHT で
チェックする (Interest が/a/b/0/1 ならば，/a ・/a/b ・/a/b/0 ・
/a/b/0/1 をすべて)
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため挿入されたエントリは親 (1 コンポ
ネント短いエントリ) へのポインタを張る (Data が daemon に到
着した際に，できるだけ多くの Interest を消費するため． (3)
で詳細を述べる)
\\end{enumerate}
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-15]{Interest 処理のオペレーショナルフロー (2)}
\\begin{itemize}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\begin{itemize}
\\item コンポーネント数の比較
\\item Name 全体の長さの比較
\\item memcmp における Binary の Name 自体の比較
\\end{itemize}
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する Exclude や
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-16]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後，
Data を返送し， NPHT と PHT から Interest を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，/a/b/0/1 ・/a/b/0 ・/a/b ・/a を探索する
\\begin{itemize}
\\item オプションによっては， Interest の fullname と NPHT のエント
リが完全一致しなくても良い場合があるため
\\item Interest には， MinSuffixComponents と MaxSuffixComponents というオプ
ションが存在し，マッチしてほしいコンポーネントの範囲を指定することができる
\\item 例えば， Interest の fullname が/a/b/0/1 ， MaxSuffixComponents が
3 の時， Data /a/b/0/1 でも Interest の要件を満たしている
きる
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-7-17]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-18]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-19]{よく分からなかった点}
\\begin{itemize}
\\item CCNx のデータ構造の中に「 ccn\\_forwarding 」と「 ccn\\_forwarding\\_entry 」
の 2 つのデータ構造があった
\\item この 2 つのデータ構造は，互いに関係がない
\\item NPE からリンクが貼られていたのは前者
\\end{itemize}
\\end{frame}

\\section{2014 年 3 月 5 日}
\\label{sec-8}
\\begin{frame}[label=sec-8-1]{}
\\end{frame}
\\begin{frame}[label=sec-8-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめ， CCNx のデータ構造について
の理解を深める
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{長期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-8-3]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-4]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-5]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-6]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-7]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item どうやって Data が人気か判断するのか， CA と同じように accession
number でアクセスするのか分からないため，ソースを読む必要があ
る
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-8]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-9]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) によって管理
される
\\begin{itemize}
\\item NPHT は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-8-10]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-11]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-12]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の prefix が\\alert{すべて}存在するかを NPHT でチェックする
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため prefix は親へのポインタを張る
\\end{enumerate}
\\end{enumerate}
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-13]{Interest 処理のオペレーショナルフロー (2)}
\\begin{enumerate}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する除外フィルタなどがあ
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-8-14]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後， Data パケットを返送し， NPHT
と PHT から Interest の name を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，\\alert{/a/b/0 ・/a/b ・/a をすべて}探索
する
\\begin{itemize}
\\item できるだけ多くの Interest を消費するため
\\item 例えば， Interest /a/b/0 が，最初の 3 コンポネントでのみのマッチを
必要としている場合，コンテンツ/a/b/0/1 が Interest/a/b/0 を満たす
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-8-15]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-16]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-17]{所感}
\\begin{itemize}
\\item CCNx のデータ構造について大まかな理解はできたと思われる
\\item 一方で，各テーブルのエントリの構造などの細かい所については触れられ
ていなかったため，ソースコードを読んでいく必要があると感じた
\\end{itemize}
\\end{frame}
% Emacs 24.3.1 (Org mode 8.2.5h)
\\end{document}" "% Created 2014-04-22 Tue 10:30
\\documentclass[dvipdfmx,11pt]{beamer}
\\usepackage{url}
\\usepackage{pxjahyper}
\\usetheme{Berlin}
\\setbeamertemplate{navigation symbols}{}
\\beamertemplatetextbibitems
\\setbeamertemplate{footline}[frame number]
\\setbeamertemplate{headline}{}


\\institute[]{大阪大学大学院情報科学研究科\\\\
            情報ネットワーク学専攻\\\\
            情報流通プラットフォーム講座 長谷川研究室 M2}
\\usetheme{default}
\\author{大杉 海斗}
\\date{\\today}
\\title{M2 Meeting}
\\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.3.1 (Org mode 8.2.5h)}}
\\begin{document}

\\maketitle

\\section{2014 年 4 月 22 日}
\\label{sec-1}
\\begin{frame}[label=sec-1-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-1-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item ディスパッチャの設計を擬似コードのレベルまで詳細化する
\\item 実験プランの作成
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-3]{擬似コードの設計概要}
\\begin{itemize}
\\item ディスパッチャとパケット処理はそれぞれスレッドで実装する
\\begin{itemize}
\\item prefix テーブルなどを共有するため
\\item Cisco は，それぞれがプロセスとして動作
\\end{itemize}
\\item 各スレッドは次のような設計になっている
\\begin{itemize}
\\item Dispatcher
\\begin{itemize}
\\item CPU0 で動作
\\item 常にパケットキューを監視
\\item packet\\_process が持つキューにパケットをエンキュー
\\end{itemize}
\\item packet\\_process
\\begin{itemize}
\\item CPU1 〜 3 で動作 (4 コアと仮定)
\\item 常に各 CPU が持つパケットキューを監視
\\item キューに入っているパケットを取り出し， process\\_input\\_*(CCNx に
よるパケット処理関数) にパケットを渡して実行
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-4]{CPU コアの省電力化}
\\begin{itemize}
\\item 使用していない CPU コアをシャットダウンすることで省電力化を行う
\\begin{itemize}
\\item /sys/devices/system/cpu/cpu 番号/online を 0 にすることでシャットダ
ウン可能
\\end{itemize}
\\item CPU コアをスリープして Idle にする方法もあるが，シャットダウンし
た場合の方が電力消費は少ない
\\item Linux kernel 2.6.18 以降は処理を少ない CPU コアに集める機能があるた
め OFF になっているか確認する (以下が 0)
\\begin{itemize}
\\item /sys/devices/system/cpu/sched\\_mc\\_power\\_savings
\\item /sys/devices/system/cpu/sched\\_smp\\_power\\_savings
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-5]{ディスパッチャが正しく動作していることを確認する実験プラン}
\\begin{itemize}
\\item root preifx が\"/a\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 ・ 2 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"・\"c\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:すべての CPU コアに負荷がかかる
\\end{itemize}
\\end{itemize}
\\end{frame}
\\section{2014 年 4 月 15 日}
\\label{sec-2}
\\begin{frame}[label=sec-2-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-2-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 前回のミーティングで議論した事を踏まえて，ディスパッチャの現状の
設計をまとめる
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力を測定する
\\begin{itemize}
\\item パケットのサイズが 1.5KB 以下の時と 4KB の時を測定する
\\begin{itemize}
\\item 分割されたパケットの再構成に必要な CPU 負荷と消費電力も見たいため
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-3]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの現状の設計をまとめた
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力は測定できていない
\\item Intel と Broadcom の 10GbE カードについて調査した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-4]{10GbE カードでパケットを転送した時のスループット}
\\begin{itemize}
\\item 下記の通り，送信相手によってスループットに大きな差が出てしまい，そ
の原因が解明できなかったため，電力を測定する段階まで至らなかった
\\item スループットの測定には iperf を使用した
\\item TCP はクラアント-サーバだけ， UDP はルータ込でも測定したが結果に
影響はなかった
\\begin{itemize}
\\item Intel の 10GbE から Chelsio の 10GbE 
\\begin{itemize}
\\item TCP 9.5Gbps
\\item UDP 800Mbps
\\end{itemize}
\\item Chelsio の 10GbE から Intel の 10GbE
\\begin{itemize}
\\item TCP 3.0Gbps
\\item UDP 690Mbps
\\end{itemize}
\\item 両方のカードともに TCP offload は on ， UDP offload は off
\\begin{itemize}
\\item TCP が UDP よりも早いのは， offload の差だと思われる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-5]{10GbE カードでパケットを転送した時の CPU 負荷}
\\begin{itemize}
\\item TCP
\\begin{itemize}
\\item iperf でパケットの送受信をしたところ，クライアント・サーバ共に 30\\%程度は
CPU を使用していた
\\end{itemize}
\\item UDP
\\begin{itemize}
\\item クライアント・サーバ・ルータの CPU 負荷はどれも非常に小さい
\\begin{itemize}
\\item ルータで IP forwarding の役割をするプロセスは分からなかったが， CPU 負
荷の高いプロセスは見られなかった
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-6]{CPU 負荷に関する考察}
\\begin{itemize}
\\item CPU 使用率が， TCP での通信の時に UDP よりも大幅に大きくなる理由
\\begin{itemize}
\\item スループットが高いため，処理するパケットの数が多い
\\item UDP にない処理 (シーケンス番号の確認など) に必要なクロック数が
多い
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-7]{測定の際に気になった点}
\\begin{itemize}
\\item iperf のサーバ側では，パケット転送が終わった後も CPU 使用率が 200\\%
や 300\\%に張り付いたりする場合が見られた
\\begin{itemize}
\\item iperf の挙動が分からないため条件や理由などは不明である
\\begin{itemize}
\\item 今後の測定では， iperf 以外にも， CPU 使用率とスループットの両
方を測定可能な nuttcp を利用したいと考えている
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-8]{10GbE NIC の調査結果}
\\begin{itemize}
\\item 選定基準
\\begin{itemize}
\\item ルータ用に Dual Port
\\item 既存のケーブルが流用できる RJ-45 Copper か CX4 Copper
\\end{itemize}
\\item Intel
\\begin{itemize}
\\item Intel ® Ethernet Converged Network Adapter X540-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/58954/Intel-Ethernet-Converged-Network-Adapter-X540-T2}
\\end{itemize}
\\item Intel ® Ethernet Converged Network Adapter X520-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/69655/Intel-Ethernet-Converged-Network-Adapter-X520-T2}
\\end{itemize}
\\end{itemize}
\\item Broadcom (すべて 10GBASE-T Transceiver with XFI)
\\begin{itemize}
\\item BCM84846
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84846}
\\end{itemize}
\\item BCM84836
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84836}
\\end{itemize}
\\item BCM84833
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84833}
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-9]{}
\\begin{itemize}
\\item 次のスライド以降，現状のディスパッチャの設計をまとめる
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-10]{ディスパッチャの設計方針}
\\begin{itemize}
\\item 同一の Root Prefix を持つパケットが並列に処理されないようにする
\\begin{itemize}
\\item NPHT の排他制御が必要となるため
\\end{itemize}
\\item CS に関連するテーブルは，パーティショニングを行い，各 CPU に排他的
に割り当てする
\\begin{itemize}
\\item Data パケットの格納・削除が多く，複数の CPU コアで共有すると排他
制御が頻発し，パフォーマンスを大きく低下させることが予想されるた
め
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-11]{ディスパッチャのテーブル構造}
\\begin{itemize}
\\item 排他制御の頻度を考慮して，パーティショニングを行うテーブルとそう
でないものに分ける
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) はパーティショニングを行わない
\\item CSL (Content Skip List) ・ SHL (Straggler Hash Table) ・ CA
(Content Array) はパーティショニングを行う
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-12]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix ・それを処理する CPU ・その Root Prefix
を持つキャッシュパーティションの対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-13]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-14]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-15]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-16]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-17]{}
\\end{frame}
\\section{2014 年 4 月 9 日}
\\label{sec-3}
\\begin{frame}[label=sec-3-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-3-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) は，パーティショニングを行う必要が
ないと予想される
\\begin{itemize}
\\item 同じ Root Prefix を持つパケットが並列に処理されない
ようにすればよい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item パケット処理を CPU に割り当てするストラテジを考える必要がある
\\begin{itemize}
\\item CPU 使用率が 150\\%となるような処理を 3 つのコアに割り当てる時，
100\\%・ 50\\%・ 0\\%， 75\\%・ 75\\%・ 0\\%， 50\\%・ 50\\%・ 50\\%と割り当てる場合で
電力消費量が変化すると予想されるため
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-4]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの設計を行った
\\begin{itemize}
\\item 実際に C でコードを書き始めている
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-5]{懸念事項}
\\begin{itemize}
\\item NPHT はパーティショニングする必要がないが， CSL (Content Skip List)
や CA (Content Array) に関しては，パーティショニングする必要があ
ると思われる
\\begin{itemize}
\\item NPHT に比べてエントリの挿入と削除が頻発する
\\end{itemize}
\\item CSL と CA をパーティショニングして，各 CPU に割り当てする場合，以
下のディスパッチャの設計では CS の機能が活かせないため，再考する必
要がある
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-6]{}
\\centering
\\includegraphics[width=0.9\\linewidth,height=0.9\\textheight]{./figure/CCN_Algorithm_detail_CSL.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-7]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix とそれを処理する CPU の対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-8]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-9]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-10]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-11]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\item 研究の観点からも，負荷が増加するごとにコアの数を増やして行くほう
が推定しやすそう
\\item 方針が決まってからフローチャートを作成する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-12]{}
\\end{frame}
\\section{2014 年 4 月 1 日}
\\label{sec-4}
\\begin{frame}[label=sec-4-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item 下図の D (ディスパッチャ) と A0 〜 A2 (NDN パケットを処理するプロ
セス) がパケットを処理するのに要するクロック数を測定する
\\begin{itemize}
\\item 下図の A0 〜 A2 がパケットを処理するのに要するクロック数は，中井さんの測定し
た結果から分かる
\\item D が処理するのに要するクロック数は，新たに計測する
\\begin{itemize}
\\item そのために，まずはディスパッチャの設計を考える必要がある
\\end{itemize}
\\end{itemize}
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item フォワーディングエンジンの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item CCNx では， FIB と PIT を NPHT (Name Prefix Hash Table) で管理して
いるため， PIT と CS を排他的に割り当てするためには， NPHT ( FIB ・
PIT) と CS をパーティショニングする必要がある
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item Cisco は， PIT と CS を同一テーブルで管理し，それぞれの CPU コアへ
排他的に割り当て， FIB は CPU コア間で共有している
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-4]{進捗状況}
\\begin{itemize}
\\item 各 CPU コアにパケット処理を割り当てするディスパッチャを設計した
\\item ポスターの原稿を修正した
\\begin{itemize}
\\item CCN の説明を追加した
\\item 武政君の研究内容 (CCN ルータのキャッシュヒット率の導出) を追加した
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-5]{ディスパッチャの要件}
\\begin{itemize}
\\item できるだけ各 CPU の使用率を均等にする
\\item パケット処理は，そのパケットの親の処理が割り当てられたのと同じ
CPU に割り当てされなければならない
\\begin{itemize}
\\item FIB エントリの最長一致検索によるパケットフォワーディングのため，
各エントリは親エントリへのリンクを張っているから
\\item パケット /a/b/0 ・/a/b ・/a は，必ず同じ CPU に割り当てされる必要がある
\\end{itemize}
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item CPU コア間で FIB を共有しているため，パケットの full-name をハッ
シュ化し，そのハッシュ値で CPU コアへと振り分けしている
\\item full-name の偏りによっては，特定 CPU コアに処理が集中する可能性が
ある
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-6]{ディスパッチャの設計}
\\begin{itemize}
\\item 2 種類の設計を考えた
\\begin{itemize}
\\item 方式 1: 現在の各 CPU コアの負荷に関係なく，入力パケットの Root
Prefix\\footnote{Root Prefix: パケットの名前を tree に見立てた時の根に当たる Prefix (例: /a/b/0 ならば/a ，/b/c/d ならば/b)} のハッシュ値によってパケット処理を割り当てする CPU コアを
決定する
\\begin{itemize}
\\item (ハッシュ値 mod n) = 1 ならばコア 1 ， = 2 ならばコア 2\\ldots{}\\ldots{}の
ようなイメージ
\\item 処理が簡単
\\item 特定の CPU コアに負荷が集中する可能性がある
\\end{itemize}
\\item 方式 2: 現在の各 CPU コアの負荷に応じて，パケット処理を割り当て
する CPU コアを変更する
\\begin{itemize}
\\item 詳細は後述
\\item 処理が複雑
\\item 特定の CPU コアへの負荷の集中を防ぐことができる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-7]{方式 2 の詳細 (1)}
\\begin{itemize}
\\item パケットの処理をどの CPU コアへ割り当てするかの選択が，パケットの
Root Prefix にのみ依存することに着目
\\begin{itemize}
\\item Root Prefix と割り当てする CPU コアの対応をテーブルで管理する
\\begin{itemize}
\\item Root Prefix ならば，それほど数がなさそう
\\end{itemize}
\\end{itemize}
\\item Key は Root Prefix のハッシュ値
\\item テーブルにない Root Prefix を持つパケットが到着した時は， CPU 負荷
の低いコアへ割り当てし，その対応をテーブルに追加
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-8]{方式 2 の詳細 (2)}
\\begin{itemize}
\\item いつまでも同じコアへとパケットを割り当てをしていては，この方式の意
味がないため，一定時間 (Time to Live で指定) 経過後にテーブル
からエントリを削除
\\begin{itemize}
\\item Time to Live はその Root Prefix を持つすべてのパケットが対応する
FIB ・ PIT ・ CS の エントリが expire するまでの時間の最大値と同
じにする必要がある
\\begin{itemize}
\\item 該当するエントリがある FIB ・ PIT ・ CS を持つ App Process へとパ
ケットの処理を割り当てするため
\\end{itemize}
\\end{itemize}
\\item App Process はパケット処理後に Time to Live にセットする値を返す
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-9]{2 つの方式に対する考え}
\\begin{itemize}
\\item 方式 2 の方が現実的であると思われる
\\begin{itemize}
\\item 方式 1 では， 各 CPU コアの負荷がコンテンツの名前空間に依存する
\\begin{itemize}
\\item コンテンツの名前は，ルータのベンダが決められるものではないため，特定の CPU コアに処理が集中すると予想される
\\end{itemize}
\\end{itemize}
\\item 方式 2 の別案として，全 CPU コアに毎回 Root Prefix で lookup を行う方法もある
\\begin{itemize}
\\item テーブルを保持する必要はないが，オーバーヘッドが大きい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-10]{パケット (Interest/Data の両方) 到着時のプロセス}
\\begin{enumerate}
\\item パケットの Root Prefix より Hash 値を計算し，その値によりディス
パッチャの持つテーブルを参照
\\item HIT 時: ディスパッチャは， App Process へとパケット処理を割り当て
し， App Process から Time to Live にセットする値 (エントリの残り
時間) を受け取る
\\item MISS 時: CPU 使用率の低いコアへとパケット処理を割り当てし，テーブ
ルにエントリを作成 (Time to Live は App Process がパケット処理時
に返却)
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-4-11]{}
\\end{frame}

\\section{2014 年 3 月 25 日}
\\label{sec-5}
\\begin{frame}[label=sec-5-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電
力消費を測定するために必要なハードウェア・ソフトウェア構成を考え
る
\\begin{itemize}
\\item ハードウェアは，専用のルータではなく，一般的な PC を想定している
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-2]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-5-3]{進捗状況}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電力消
費を測定するために必要なハードウェア・ソフトウェア構成を考えた
\\item マルチコア CPU 環境におけるクロック数の測定方法を検討した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-4]{現在考えられる課題一覧}
\\begin{itemize}
\\item マルチスレッドに対応した NDN ソフトウェアの作成
\\begin{itemize}
\\item 特定 CPU コアへのスレッドの割り当て (おそらく下の API を用いることで可能)
\\begin{itemize}
\\item sched\\_get\\_affinity ()
\\item sched\\_set\\_affinity ()
\\item \\url{http:linuxjm.sourceforge.jp/html/LDP_man-pages/man2/sched_setaffinity.2.html}
\\end{itemize}
\\end{itemize}
\\item CPU がマルチコアの時に電力消費量を推定できるモデルの提案
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-5]{本日のミーティングで議論したいこと}
\\begin{itemize}
\\item NDN ルータのソフトウェア構成およびハードウェア構成に問題がないか
\\item 今後行っていく作業の優先順位付け
\\item 研究室紹介に使うポスターの内容
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-6]{NDN ルータのハードウェア構成}
\\begin{itemize}
\\item CPU: Intel Xeon E3-1220 (3.1GHz x 4 コア)
\\begin{itemize}
\\item ハイパースレッディングとターボブーストはとりあえず無効化する
\\end{itemize}
\\item Memory: DDR3 16GB,1600MHz
\\begin{itemize}
\\item FIB ・ PIT ・ CS のテーブルサイズについて今は考慮しないため，
Memory サイズはそれほど考慮しない
\\end{itemize}
\\item HDD: Western Digital 2TB SATA 3.5 inch \"WD2000FYYX\"
\\begin{itemize}
\\item Memory と同様であまり考慮しない
\\end{itemize}
\\item NIC: Intel 10-Gigabit Ethernet x 2
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-7]{NDN パケットフロー}
\\begin{itemize}
\\item 4 コアなので D と A0 〜 3 にそれぞれ 1 コアずつ割り当てる
\\end{itemize}
\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}
\\begin{frame}[label=sec-5-8]{NDN ルータのソフトウェア構成の概要}
\\begin{itemize}
\\item ソフトウェアの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item 一方で， PIT と CS に関しては，複数の CPU が同一エントリへアクセス
した時の排他制御によるパフォーマンスの低下が大きいと予想されるため，
PIT と CS はパーティショニングを行う
\\begin{itemize}
\\item マルチコアへのスレッドの割り当てなどは Cisco のデモを参考にする
\\end{itemize}
\\item ソフトウェアでは次のことを行う
\\begin{itemize}
\\item NDN パケットのフォワーディング処理
\\item CPU コアへのスレッドの割り当て (ディスパッチ処理)
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-9]{NDN ルータのソフトウェア}
\\begin{itemize}
\\item パケットの full-name のハッシュ値によって，パケットの処理を各 CPU コ
アに振り分ける
\\begin{itemize}
\\item NPHT (FIB ・ PIT) と CS を 3 つにパーティショニングする
\\begin{itemize}
\\item NPHT は， bucket が 6 つだとすると， 0 ・ 1 はテーブル 1 とし
てコア 1 ， 2 ・ 3 はテーブル 2 としてコア 2 ， 4 ・ 5 はテー
ブル 3 としてコア 3 というように割り当てする
\\item FIB までパーティショニングされてしまい， parent にリンクを貼
ることによる fast lookup が使えないという問題がある
\\end{itemize}
\\end{itemize}
\\item PIT (CS) の lookup 処理および insert 処理の前に，処理対象のパケッ
トの full-name をハッシュ化
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-10]{}
\\includegraphics[width=.9\\linewidth]{./figure/CCN_Algorithm_detail.pdf}
\\end{frame}

\\begin{frame}[label=sec-5-11]{Interest パケットがデーモンに到着した時のシーケンス}
\\begin{enumerate}
\\item パケットを name 部とオプション部に parse
\\item duplication check (重複検知)
\\item パケットの name 部からハッシュ値を計算， Prefix Seek の処理以降を
スレッドにし， ハッシュ値に応じた CPU コアに割り当て
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-5-12]{マルチコア CPU 環境におけるクロック数の測定方法}
\\begin{itemize}
\\item おそらく中井さんが用いた RDTSC 命令を用いることで，マルチコア CPU で
もクロック数の測定が可能である
\\begin{itemize}
\\item タイムスタンプカウンタ (TSC) が， Invariant TSC ならばマルチコ
ア環境でも正確にクロック数を測定可能である
\\begin{itemize}
\\item \\url{http:www.02.246.ne.jp/~torutk/cxx/clock/cpucounter.html}
\\end{itemize}
\\item 本実験で使う予定の Intel Xeon E3-1220 は Invariant TSC であることを確認した
\\end{itemize}
\\item さらに， Turbo boost でクロック数が変化した場合でも正確にクロック
を測定できる
\\item 一方で，マルチ CPU 環境ではクロック測定が困難であると予想される
\\begin{itemize}
\\item クロック数をリセットする信号がプロセッサ単位でしか送信できない
ため
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-5-13]{}
\\end{frame}

\\section{2014 年 3 月 17 日}
\\label{sec-6}
\\begin{frame}[label=sec-6-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えるかどうかを確認する
\\item 「 named data networking on a router forwarding at 20 gbps and
beyond 」を参考に， 20Gb や 40Gb の転送速度を出せるソフトウェアルー
タを作る時に，必要となるハードウェアの構成を考える
\\item CCNx のデータ構造とオペレーショナルフローについてまとめた資料の誤
りを修正する
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-2]{研究目標}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標 (5 月)}%x
\\begin{itemize}
\\item 現在，ルータのモデル化は， CPU がシングルコアの時のみできているた
め，モデルをマルチコア or マルチ CPU に対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-6-3]{目標達成に向けてのアプローチ}
\\begin{enumerate}
\\item 中井さんの資料および CCNx のソースコードを読み， CCNx ver8.1 の処理をブロッ
クに分割し，それぞれのブロックの処理に必要なクロック数を測定する
(最新 ver に拘らないならば，中井さんが実験を行った ver7.2 を使えばよ
 いため，このプロセスは飛ばすことができる)
\\item 1.で計測されたクロック数を基に， CCNx の挙動を模倣するプログラムを
作成する
\\begin{itemize}
\\item CCNx はマルチスレッドに対応していない (?) ため
\\item CCNx における各ブロックの処理にかかるクロック数だけ， dummy の処
理を行わせる
\\item NDN パケットの送受信するタイミングで， UDP パケットを送受信す
る
\\end{itemize}
\\item 2.で作成したプログラムを動作させた PC の電力消費を測定する
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-6-4]{進捗状況}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えることを確認した
\\begin{itemize}
\\item 他の PC とケーブルで繋ぎ， ping が通ることを確認
\\item 当該 PC の 10Gigabit-Ethernet カードを接続するスロット数 (PCI-Express x8)
は 1 つで，カードのインターフェース数は 2 つのため，最大で
20Gbps までしか測定できない
\\end{itemize}
\\item 「 named data networking on a router forwarding at
20 Gbps and beyond 」を読み必要なハードウェア構成について考えた
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-5]{議論したいこと}
\\begin{itemize}
\\item 今回ハードウェアの構成を考えたが， CCNx の動作で 20Gbps を達成するのは困難である
と予想された
\\item したがって，何にフォーカスを当て (コントリビューションは何か) ，
何を優先すべきかを議論したいと考えている
\\begin{itemize}
\\item 中井さんの提案したモデルを， CCNx の最新版に対応させること
\\item 中井さんの提案したモデルを，マルチコア or マルチ CPU に対応させること
\\item 現実的なアクセスルータを考慮して， 20Gbps や 40Gbps のスループットを達成できるハードウェアと，ソフ
トウェアを調査し，その電力消費量を測定すること
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-6]{}
\\begin{itemize}
\\item 次ページより，「 named data networking on a router forwarding at
20 Gbps and beyond 」の内容をまとめる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-7]{概要}
\\begin{itemize}
\\item Cisco ASR9000 上の Linux で NDN フォワーディングエンジンを動作さ
せ，そのパフォーマンスを測定している
\\item NDN フォワーディングエンジンは CCNx ではなく， CS ・ FIB ・ PIT のデータ構造も異なっ
ている
\\item シミュレーションの結果， Interest および Data のフォワーディング
スループットが， 20Gbps を超えることを示している
\\begin{itemize}
\\item シミュレーションでは，実際には NIC を通したパケットの送受信を行っておらず，
ファイルからパケットを読み込むことで擬似的なフォワーディング処理
を行っている
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-8]{Cisco の NDN ソフトウェアルータのハードウェア構成}
\\begin{itemize}
\\item モデル名: Cisco ASR9000
\\item CPU: Intel Xeon (Westmeie-EP) 2.0GHz 6 コア (Hyper-threading 有) * 2
\\item LAN: Intel Niantic 10Gigabit Ethernet  * 4
\\item Storage: 3.2TB SSD (NDN の Cache Storage として使用)
\\item 64bit Linux 上のソフトウェアでパケットフォワーディングを行ってい
る
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-9]{NDN フォワーディングエンジン}
\\begin{itemize}
\\item CCNx とはデータ構造や look up の方法が大きく異なる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-10]{FIB}
\\begin{itemize}
\\item FIB look up の方法が CCNx と異なる (あまり関係なさそうなので割愛)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-11]{CS ・ PIT}
\\begin{itemize}
\\item CS と PIT の管理は 1 つのハッシュテーブルで行い， look up は同時に
行う
\\begin{itemize}
\\item どちらも full-name を key とするため
\\item エントリが CS のものか PIT のものかは 1bit の flag で判断する
\\end{itemize}
\\item PIT (CS/PIT) を CPU の各コア (thread) に分割する
\\begin{itemize}
\\item 複数のコアで PIT を共有するとパフォーマンスが落ちるため
\\item Interest および Data の full-name のハッシュで PIT を CPU コア
(thread) に振り分け
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-12]{NDN パケットのフロー}
\\begin{itemize}
\\item App process (A0 〜 A7) で， NDN フォワーディング処理をすべて行う
(CS/PIT look up ， FIB look up)
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.6\\textheight]{./figure/NDN_packet_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-13]{シミュレーション結果}
\\begin{itemize}
\\item 16 個の IRCache URL のトレースから 1300 万 Interest を作成し，シミュレー
ションを行っている
\\item 異なる CPU コア上で動作させるスレッド数の増加に伴いパフォーマンスは向上している
\\item FIB と PIT のサイズはパフォーマンスにほとんど影響を与えていない
\\begin{itemize}
\\item PIT/CS サイズが向上するとパフォーマンスが低下していることから，
PIT/CS look up でほとんどヒットせず，エントリの探索に時間がかかっ
ただけになっているからではないかと思われる
\\end{itemize}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.4\\textheight]{./figure/performance_of_NDN.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-14]{20Gbps を達成する時に必要な CPU}
\\begin{itemize}
\\item 29.78G (clocks/s) を達成できるもの
\\begin{itemize}
\\item 1 秒間に処理するパケット数を算出 (パケットサイズ 2KB は， Interest と Data が同
数であると仮定し，標準チャンクサイズ 4KB を 2 で割って算出
(Interest のサイズは小さいので無視))
\\begin{itemize}
\\item 20Gbps / (2K*8) = 1.25M (packet/s)
\\end{itemize}
\\item Interest と Data のペアの処理にかかる合計クロック数 48787 をかけ
て 2 で割る (こちらも Interest と Data が同数であると仮定． CS
HIT0\\%のとき．中井さんの論文から算出)
\\begin{itemize}
\\item 1.25M * 48784 / 2  = 30491.88 M (clocks/s)
= 29.78 G (clocks/s)
\\end{itemize}
\\end{itemize}
\\item 上の計算仮定には， XML の処理が入っていない．また，パケットサイズ
を 2KB としているが， Cisco は 500B としている．したがって，上記の
結果は甘く見積もっており， CCNx の挙動をそのまま模倣すると CPU の処
理が間に合わないと予想される．
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-15]{20Gbps を達成する時に必要な主記憶}
\\begin{itemize}
\\item Cisco のデモから， FIB および PIT のサイズはあまりスループットに影響し
ていないため， 1Gbyte もあれば十分ではないかと思われる
\\item 一方で， FIB ・ PIT の fast look up は時間のかかる処理であるため，
主記憶の速度は重要である
\\begin{itemize}
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-16]{20Gbps を達成する時に必要なネットワークインターフェース}
\\begin{itemize}
\\item 10Gigabit-Ethernet * 4
\\begin{itemize}
\\item Cisco と同様
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-17]{}
\\end{frame}

\\section{2014 年 3 月 12 日}
\\label{sec-7}
\\begin{frame}[label=sec-7-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめたが，説明不足な部分があったた
め，コメントに基づいて更新を行なう
\\item 今後どのように研究を進めていくかを本日のミーティングで検討する
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-7-2]{進捗状況}
\\begin{itemize}
\\item 中井さんから，以下のことを引き継ぎしてもらった
\\begin{itemize}
\\item CCNx のソースコード中に RDTSC を埋め込んでクロック数を測定する方法
\\item 実験のネットワークへのアクセス方法と実験用スクリプトの使い方
\\end{itemize}
\\item 3/24 (月) に，実機を使って電力消費の測定を行なう (CCNx は，中井
さんが使っていたのと同じ ver7.1 を使用する)
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-3]{今後の予定 (仮)}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」と実
際のソースコードを読んだことで， CCNx の概要が分かってきたと思うた
め，ソースコードを読み進めつつ，ソースコード中のどこでクロックを
測定するべきか考えて行きたいと思っている
\\item 並行して， CCNx の理解を深めるため， CCNx1.0 へのロードマップを読み
進めていきたいと考えている (100 ページ程度あるため 2 〜 3 週間を目安に
考えている)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-4]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-5]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-6]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-7]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-8]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item ver8.1 では， SHT らしきものが見つけられなかった (重要ならばもう少し時間
をかけてソースコードを読みたいと思います)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-9]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\begin{itemize}
\\item 詳細は次ページ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-10]{CSL におけるコンテンツ名順の lookup}
\\begin{itemize}
\\item CSL では， Data がコンテンツの名前順に整列されている
\\item CSL での lookup のアルゴリズム挙動は次の通り
\\begin{enumerate}
\\item 右にポインタを辿り検索対象コンテンツ名とノードを比較する．
\\begin{itemize}
\\item コンテンツ名 $<$ ノード 再び 1 へ
\\item コンテツ名 $>$ ノード 元のノードへ戻り，階層を 1 つ下げて再び
1 へ，最下層なら 2 へ
\\item コンテンツ名 = ノード マッチしたので探索終了
\\end{itemize}
\\item 探索するコンテンツが存在しないので探索終了
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.9\\linewidth,height=0.5\\textheight]{./figure/cs_skiplist.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-11]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) のエントリ
Name Prefix Entry (NPE) によって管理される
\\begin{itemize}
\\item NPE は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\begin{block}{PEs}%x
\\begin{itemize}
\\item エントリ同士は，双方向でリンクされている
\\item メンバ変数
\\begin{itemize}
\\item 元の interest (unsigned int 型なので，おそらくバイナリのまま．
コメントによるとマッチングに使用する)
\\item 転送した interest のメッセージとそのサイズ
\\end{itemize}
\\end{itemize}
\\end{block}
\\begin{block}{FIEs}%x
\\begin{itemize}
\\item NPE 中に存在
\\item メンバ変数
\\begin{itemize}
\\item face の id
\\item expire までの残り時間
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-7-12]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\begin{itemize}
\\item Interest: process\\_incoming\\_interest
\\item Data: process\\_incoming\\_content
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-13]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-14]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の nameprefix が\\alert{すべて}存在するかを NPHT で
チェックする (Interest が/a/b/0/1 ならば，/a ・/a/b ・/a/b/0 ・
/a/b/0/1 をすべて)
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため挿入されたエントリは親 (1 コンポ
ネント短いエントリ) へのポインタを張る (Data が daemon に到
着した際に，できるだけ多くの Interest を消費するため． (3)
で詳細を述べる)
\\end{enumerate}
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-15]{Interest 処理のオペレーショナルフロー (2)}
\\begin{itemize}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\begin{itemize}
\\item コンポーネント数の比較
\\item Name 全体の長さの比較
\\item memcmp における Binary の Name 自体の比較
\\end{itemize}
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する Exclude や
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-16]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後，
Data を返送し， NPHT と PHT から Interest を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，/a/b/0/1 ・/a/b/0 ・/a/b ・/a を探索する
\\begin{itemize}
\\item オプションによっては， Interest の fullname と NPHT のエント
リが完全一致しなくても良い場合があるため
\\item Interest には， MinSuffixComponents と MaxSuffixComponents というオプ
ションが存在し，マッチしてほしいコンポーネントの範囲を指定することができる
\\item 例えば， Interest の fullname が/a/b/0/1 ， MaxSuffixComponents が
3 の時， Data /a/b/0/1 でも Interest の要件を満たしている
きる
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-7-17]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-18]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-19]{よく分からなかった点}
\\begin{itemize}
\\item CCNx のデータ構造の中に「 ccn\\_forwarding 」と「 ccn\\_forwarding\\_entry 」
の 2 つのデータ構造があった
\\item この 2 つのデータ構造は，互いに関係がない
\\item NPE からリンクが貼られていたのは前者
\\end{itemize}
\\end{frame}

\\section{2014 年 3 月 5 日}
\\label{sec-8}
\\begin{frame}[label=sec-8-1]{}
\\end{frame}
\\begin{frame}[label=sec-8-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめ， CCNx のデータ構造について
の理解を深める
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{長期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-8-3]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-4]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-5]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-6]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-7]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item どうやって Data が人気か判断するのか， CA と同じように accession
number でアクセスするのか分からないため，ソースを読む必要があ
る
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-8]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-9]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) によって管理
される
\\begin{itemize}
\\item NPHT は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-8-10]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-11]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-12]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の prefix が\\alert{すべて}存在するかを NPHT でチェックする
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため prefix は親へのポインタを張る
\\end{enumerate}
\\end{enumerate}
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-13]{Interest 処理のオペレーショナルフロー (2)}
\\begin{enumerate}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する除外フィルタなどがあ
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-8-14]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後， Data パケットを返送し， NPHT
と PHT から Interest の name を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，\\alert{/a/b/0 ・/a/b ・/a をすべて}探索
する
\\begin{itemize}
\\item できるだけ多くの Interest を消費するため
\\item 例えば， Interest /a/b/0 が，最初の 3 コンポネントでのみのマッチを
必要としている場合，コンテンツ/a/b/0/1 が Interest/a/b/0 を満たす
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-8-15]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-16]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-17]{所感}
\\begin{itemize}
\\item CCNx のデータ構造について大まかな理解はできたと思われる
\\item 一方で，各テーブルのエントリの構造などの細かい所については触れられ
ていなかったため，ソースコードを読んでいく必要があると感じた
\\end{itemize}
\\end{frame}
% Emacs 24.3.1 (Org mode 8.2.5h)
\\end{document}" #("** 消費電力推定の実験プラン
   - 
   - 
" 0 1 (face org-level-2 fontified t) 1 3 (face org-level-2 fontified t) 3 15 (face org-level-2 fontified t) 15 16 (fontified t) 16 19 (fontified t) 19 21 (fontified t) 21 22 (fontified t) 22 27 (fontified t) 27 28 (fontified t)) "% Created 2014-04-22 Tue 10:05
\\documentclass[dvipdfmx,11pt]{beamer}
\\usepackage{url}
\\usepackage{pxjahyper}
\\usetheme{Berlin}
\\setbeamertemplate{navigation symbols}{}
\\beamertemplatetextbibitems
\\setbeamertemplate{footline}[frame number]
\\setbeamertemplate{headline}{}


\\institute[]{大阪大学大学院情報科学研究科\\\\
            情報ネットワーク学専攻\\\\
            情報流通プラットフォーム講座 長谷川研究室 M2}
\\usetheme{default}
\\author{大杉 海斗}
\\date{\\today}
\\title{M2 Meeting}
\\hypersetup{
  pdfkeywords={},
  pdfsubject={},
  pdfcreator={Emacs 24.3.1 (Org mode 8.2.5h)}}
\\begin{document}

\\maketitle

\\section{2014 年 4 月 22 日}
\\label{sec-1}
\\begin{frame}[label=sec-1-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-1-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item ディスパッチャの設計を擬似コードのレベルまで詳細化する
\\item 実験プランの作成
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-3]{擬似コードの設計概要}
\\begin{itemize}
\\item ディスパッチャとパケット処理はそれぞれスレッドで実装する
\\begin{itemize}
\\item prefix テーブルなどを共有するため
\\item Cisco は，それぞれがプロセスとして動作
\\end{itemize}
\\item 各スレッドは次のような設計になっている
\\begin{itemize}
\\item Dispatcher
\\begin{itemize}
\\item CPU0 で動作
\\item 常にパケットキューを監視
\\item packet\\_process が持つキューにパケットをエンキュー
\\end{itemize}
\\item packet\\_process
\\begin{itemize}
\\item CPU1 〜 3 で動作 (4 コアと仮定)
\\item 常に各 CPU が持つパケットキューを監視
\\item キューに入っているパケットを取り出し， process\\_input\\_*(CCNx に
よるパケット処理関数) にパケットを渡して実行
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-4]{CPU コアの省電力化}
\\begin{itemize}
\\item 使用していない CPU コアをシャットダウンすることで省電力化を行う
\\begin{itemize}
\\item /sys/devices/system/cpu/cpu 番号/online を 0 にすることでシャットダ
ウン可能
\\end{itemize}
\\item CPU コアをスリープして Idle にする方法もあるが，シャットダウンし
た場合の方が電力消費は少ない
\\item Linux kernel 2.6.18 以降は処理を少ない CPU コアに集める機能があるた
め OFF になっているか確認する (以下が 0)
\\begin{itemize}
\\item /sys/devices/system/cpu/sched\\_mc\\_power\\_savings
\\item /sys/devices/system/cpu/sched\\_smp\\_power\\_savings
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-1-5]{ディスパッチャが正しく動作していることを確認する実験プラン}
\\begin{itemize}
\\item root preifx が\"/a\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:CPU コア 0 ・ 1 ・ 2 に負荷がかかる
\\end{itemize}
\\item root preifx が\"/a\"・\"/b\"・\"c\"のパケットを連続で送信
\\begin{itemize}
\\item 期待される結果:すべての CPU コアに負荷がかかる
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-1-6]{消費電力推定の実験プラン}
\\end{frame}

\\section{2014 年 4 月 15 日}
\\label{sec-2}
\\begin{frame}[label=sec-2-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-2-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 前回のミーティングで議論した事を踏まえて，ディスパッチャの現状の
設計をまとめる
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力を測定する
\\begin{itemize}
\\item パケットのサイズが 1.5KB 以下の時と 4KB の時を測定する
\\begin{itemize}
\\item 分割されたパケットの再構成に必要な CPU 負荷と消費電力も見たいため
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-3]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの現状の設計をまとめた
\\item 10GbE カードでパケットを転送した時の CPU 負荷と消費電力は測定できていない
\\item Intel と Broadcom の 10GbE カードについて調査した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-4]{10GbE カードでパケットを転送した時のスループット}
\\begin{itemize}
\\item 下記の通り，送信相手によってスループットに大きな差が出てしまい，そ
の原因が解明できなかったため，電力を測定する段階まで至らなかった
\\item スループットの測定には iperf を使用した
\\item TCP はクラアント-サーバだけ， UDP はルータ込でも測定したが結果に
影響はなかった
\\begin{itemize}
\\item Intel の 10GbE から Chelsio の 10GbE 
\\begin{itemize}
\\item TCP 9.5Gbps
\\item UDP 800Mbps
\\end{itemize}
\\item Chelsio の 10GbE から Intel の 10GbE
\\begin{itemize}
\\item TCP 3.0Gbps
\\item UDP 690Mbps
\\end{itemize}
\\item 両方のカードともに TCP offload は on ， UDP offload は off
\\begin{itemize}
\\item TCP が UDP よりも早いのは， offload の差だと思われる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-5]{10GbE カードでパケットを転送した時の CPU 負荷}
\\begin{itemize}
\\item TCP
\\begin{itemize}
\\item iperf でパケットの送受信をしたところ，クライアント・サーバ共に 30\\%程度は
CPU を使用していた
\\end{itemize}
\\item UDP
\\begin{itemize}
\\item クライアント・サーバ・ルータの CPU 負荷はどれも非常に小さい
\\begin{itemize}
\\item ルータで IP forwarding の役割をするプロセスは分からなかったが， CPU 負
荷の高いプロセスは見られなかった
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-6]{CPU 負荷に関する考察}
\\begin{itemize}
\\item CPU 使用率が， TCP での通信の時に UDP よりも大幅に大きくなる理由
\\begin{itemize}
\\item スループットが高いため，処理するパケットの数が多い
\\item UDP にない処理 (シーケンス番号の確認など) に必要なクロック数が
多い
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-7]{測定の際に気になった点}
\\begin{itemize}
\\item iperf のサーバ側では，パケット転送が終わった後も CPU 使用率が 200\\%
や 300\\%に張り付いたりする場合が見られた
\\begin{itemize}
\\item iperf の挙動が分からないため条件や理由などは不明である
\\begin{itemize}
\\item 今後の測定では， iperf 以外にも， CPU 使用率とスループットの両
方を測定可能な nuttcp を利用したいと考えている
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-8]{10GbE NIC の調査結果}
\\begin{itemize}
\\item 選定基準
\\begin{itemize}
\\item ルータ用に Dual Port
\\item 既存のケーブルが流用できる RJ-45 Copper か CX4 Copper
\\end{itemize}
\\item Intel
\\begin{itemize}
\\item Intel ® Ethernet Converged Network Adapter X540-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/58954/Intel-Ethernet-Converged-Network-Adapter-X540-T2}
\\end{itemize}
\\item Intel ® Ethernet Converged Network Adapter X520-T2
\\begin{itemize}
\\item \\url{http:ark.intel.com/ja/products/69655/Intel-Ethernet-Converged-Network-Adapter-X520-T2}
\\end{itemize}
\\end{itemize}
\\item Broadcom (すべて 10GBASE-T Transceiver with XFI)
\\begin{itemize}
\\item BCM84846
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84846}
\\end{itemize}
\\item BCM84836
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84836}
\\end{itemize}
\\item BCM84833
\\begin{itemize}
\\item \\url{http:ja.broadcom.com/products/Physical-Layer/10-Gigabit-Ethernet-PHYs/BCM84833}
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-9]{}
\\begin{itemize}
\\item 次のスライド以降，現状のディスパッチャの設計をまとめる
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-10]{ディスパッチャの設計方針}
\\begin{itemize}
\\item 同一の Root Prefix を持つパケットが並列に処理されないようにする
\\begin{itemize}
\\item NPHT の排他制御が必要となるため
\\end{itemize}
\\item CS に関連するテーブルは，パーティショニングを行い，各 CPU に排他的
に割り当てする
\\begin{itemize}
\\item Data パケットの格納・削除が多く，複数の CPU コアで共有すると排他
制御が頻発し，パフォーマンスを大きく低下させることが予想されるた
め
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-11]{ディスパッチャのテーブル構造}
\\begin{itemize}
\\item 排他制御の頻度を考慮して，パーティショニングを行うテーブルとそう
でないものに分ける
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) はパーティショニングを行わない
\\item CSL (Content Skip List) ・ SHL (Straggler Hash Table) ・ CA
(Content Array) はパーティショニングを行う
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-12]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix ・それを処理する CPU ・その Root Prefix
を持つキャッシュパーティションの対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-2-13]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-14]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-15]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-2-16]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-2-17]{}
\\end{frame}
\\section{2014 年 4 月 9 日}
\\label{sec-3}
\\begin{frame}[label=sec-3-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-3-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item NPHT (Name Prefix Hash Table) は，パーティショニングを行う必要が
ないと予想される
\\begin{itemize}
\\item 同じ Root Prefix を持つパケットが並列に処理されない
ようにすればよい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item パケット処理を CPU に割り当てするストラテジを考える必要がある
\\begin{itemize}
\\item CPU 使用率が 150\\%となるような処理を 3 つのコアに割り当てる時，
100\\%・ 50\\%・ 0\\%， 75\\%・ 75\\%・ 0\\%， 50\\%・ 50\\%・ 50\\%と割り当てる場合で
電力消費量が変化すると予想されるため
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-4]{進捗状況}
\\begin{itemize}
\\item ディスパッチャの設計を行った
\\begin{itemize}
\\item 実際に C でコードを書き始めている
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-5]{懸念事項}
\\begin{itemize}
\\item NPHT はパーティショニングする必要がないが， CSL (Content Skip List)
や CA (Content Array) に関しては，パーティショニングする必要があ
ると思われる
\\begin{itemize}
\\item NPHT に比べてエントリの挿入と削除が頻発する
\\end{itemize}
\\item CSL と CA をパーティショニングして，各 CPU に割り当てする場合，以
下のディスパッチャの設計では CS の機能が活かせないため，再考する必
要がある
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-6]{}
\\centering
\\includegraphics[width=0.9\\linewidth,height=0.9\\textheight]{./figure/CCN_Algorithm_detail_CSL.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-7]{ディスパッチャのデータ構造}
\\begin{itemize}
\\item prefix\\_table: Root Prefix とそれを処理する CPU の対応を保持
\\item packet\\_queue: パケット処理を行う各 CPU は，パケットを格納しておくキューを専有
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-8]{ディスパッチャの設計}
\\begin{itemize}
\\item CPU を，到着パケットを各 CPU が専有するキューに入れる\\alert{パケットキューイング CPU (1 個)}と\\alert{パケット処理 CPU (N-1 個)}に分ける
\\begin{itemize}
\\item パケットキューイング CPU: パケットが到着した時，パケットを，そ
のパケットを処理する CPU のキューにエンキューする
\\begin{itemize}
\\item prefix\\_table を参照して割り当てる CPU を決定する
\\end{itemize}
\\item パケット処理 CPU: キューを監視し，キュー内にパケットがあれば，
デキューして処理
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-3-9]{ディスパッチャのフローチャート (パケットキューイング CPU)}
\\centering
\\includegraphics[width=0.7\\linewidth,height=0.8\\textheight]{./figure/Dispatcher_flowchart_dispatcher.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-10]{ディスパッチャのフローチャート (パケット処理 CPU)}
\\centering
\\includegraphics[width=0.4\\linewidth,height=0.9\\textheight]{./figure/Dispatcher_flowchart_cpu_allocation.pdf}
\\end{frame}

\\begin{frame}[label=sec-3-11]{CPU コアの選択処理}
\\begin{itemize}
\\item できるだけ少ない CPU でパケット処理を行う
\\begin{itemize}
\\item CPU 負荷が軽いときに特定 CPU コアへ処理を集め，他の CPU コアをスリー
プさせる省電力化手法を考慮
\\begin{itemize}
\\item 消費電力削減が， GreenICN の目標であるため，消費電力推定のモデ
ル化対象のルータも省電力機構を備えていると仮定
\\end{itemize}
\\item 研究の観点からも，負荷が増加するごとにコアの数を増やして行くほう
が推定しやすそう
\\item 方針が決まってからフローチャートを作成する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-3-12]{}
\\end{frame}
\\section{2014 年 4 月 1 日}
\\label{sec-4}
\\begin{frame}[label=sec-4-1]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-2]{前回ミーティングのまとめ (1)}
\\begin{itemize}
\\item 下図の D (ディスパッチャ) と A0 〜 A2 (NDN パケットを処理するプロ
セス) がパケットを処理するのに要するクロック数を測定する
\\begin{itemize}
\\item 下図の A0 〜 A2 がパケットを処理するのに要するクロック数は，中井さんの測定し
た結果から分かる
\\item D が処理するのに要するクロック数は，新たに計測する
\\begin{itemize}
\\item そのために，まずはディスパッチャの設計を考える必要がある
\\end{itemize}
\\end{itemize}
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-3]{前回ミーティングのまとめ (2)}
\\begin{itemize}
\\item フォワーディングエンジンの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item CCNx では， FIB と PIT を NPHT (Name Prefix Hash Table) で管理して
いるため， PIT と CS を排他的に割り当てするためには， NPHT ( FIB ・
PIT) と CS をパーティショニングする必要がある
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item Cisco は， PIT と CS を同一テーブルで管理し，それぞれの CPU コアへ
排他的に割り当て， FIB は CPU コア間で共有している
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-4]{進捗状況}
\\begin{itemize}
\\item 各 CPU コアにパケット処理を割り当てするディスパッチャを設計した
\\item ポスターの原稿を修正した
\\begin{itemize}
\\item CCN の説明を追加した
\\item 武政君の研究内容 (CCN ルータのキャッシュヒット率の導出) を追加した
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-5]{ディスパッチャの要件}
\\begin{itemize}
\\item できるだけ各 CPU の使用率を均等にする
\\item パケット処理は，そのパケットの親の処理が割り当てられたのと同じ
CPU に割り当てされなければならない
\\begin{itemize}
\\item FIB エントリの最長一致検索によるパケットフォワーディングのため，
各エントリは親エントリへのリンクを張っているから
\\item パケット /a/b/0 ・/a/b ・/a は，必ず同じ CPU に割り当てされる必要がある
\\end{itemize}
\\end{itemize}

\\begin{block}{参考: Cisco の設計}%x
\\begin{itemize}
\\item CPU コア間で FIB を共有しているため，パケットの full-name をハッ
シュ化し，そのハッシュ値で CPU コアへと振り分けしている
\\item full-name の偏りによっては，特定 CPU コアに処理が集中する可能性が
ある
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-4-6]{ディスパッチャの設計}
\\begin{itemize}
\\item 2 種類の設計を考えた
\\begin{itemize}
\\item 方式 1: 現在の各 CPU コアの負荷に関係なく，入力パケットの Root
Prefix\\footnote{Root Prefix: パケットの名前を tree に見立てた時の根に当たる Prefix (例: /a/b/0 ならば/a ，/b/c/d ならば/b)} のハッシュ値によってパケット処理を割り当てする CPU コアを
決定する
\\begin{itemize}
\\item (ハッシュ値 mod n) = 1 ならばコア 1 ， = 2 ならばコア 2\\ldots{}\\ldots{}の
ようなイメージ
\\item 処理が簡単
\\item 特定の CPU コアに負荷が集中する可能性がある
\\end{itemize}
\\item 方式 2: 現在の各 CPU コアの負荷に応じて，パケット処理を割り当て
する CPU コアを変更する
\\begin{itemize}
\\item 詳細は後述
\\item 処理が複雑
\\item 特定の CPU コアへの負荷の集中を防ぐことができる
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-7]{方式 2 の詳細 (1)}
\\begin{itemize}
\\item パケットの処理をどの CPU コアへ割り当てするかの選択が，パケットの
Root Prefix にのみ依存することに着目
\\begin{itemize}
\\item Root Prefix と割り当てする CPU コアの対応をテーブルで管理する
\\begin{itemize}
\\item Root Prefix ならば，それほど数がなさそう
\\end{itemize}
\\end{itemize}
\\item Key は Root Prefix のハッシュ値
\\item テーブルにない Root Prefix を持つパケットが到着した時は， CPU 負荷
の低いコアへ割り当てし，その対応をテーブルに追加
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-8]{方式 2 の詳細 (2)}
\\begin{itemize}
\\item いつまでも同じコアへとパケットを割り当てをしていては，この方式の意
味がないため，一定時間 (Time to Live で指定) 経過後にテーブル
からエントリを削除
\\begin{itemize}
\\item Time to Live はその Root Prefix を持つすべてのパケットが対応する
FIB ・ PIT ・ CS の エントリが expire するまでの時間の最大値と同
じにする必要がある
\\begin{itemize}
\\item 該当するエントリがある FIB ・ PIT ・ CS を持つ App Process へとパ
ケットの処理を割り当てするため
\\end{itemize}
\\end{itemize}
\\item App Process はパケット処理後に Time to Live にセットする値を返す
\\end{itemize}

\\includegraphics[width=.9\\linewidth]{./figure/dispatcher_table.pdf}
\\end{frame}

\\begin{frame}[label=sec-4-9]{2 つの方式に対する考え}
\\begin{itemize}
\\item 方式 2 の方が現実的であると思われる
\\begin{itemize}
\\item 方式 1 では， 各 CPU コアの負荷がコンテンツの名前空間に依存する
\\begin{itemize}
\\item コンテンツの名前は，ルータのベンダが決められるものではないため，特定の CPU コアに処理が集中すると予想される
\\end{itemize}
\\end{itemize}
\\item 方式 2 の別案として，全 CPU コアに毎回 Root Prefix で lookup を行う方法もある
\\begin{itemize}
\\item テーブルを保持する必要はないが，オーバーヘッドが大きい
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-4-10]{パケット (Interest/Data の両方) 到着時のプロセス}
\\begin{enumerate}
\\item パケットの Root Prefix より Hash 値を計算し，その値によりディス
パッチャの持つテーブルを参照
\\item HIT 時: ディスパッチャは， App Process へとパケット処理を割り当て
し， App Process から Time to Live にセットする値 (エントリの残り
時間) を受け取る
\\item MISS 時: CPU 使用率の低いコアへとパケット処理を割り当てし，テーブ
ルにエントリを作成 (Time to Live は App Process がパケット処理時
に返却)
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-4-11]{}
\\end{frame}

\\section{2014 年 3 月 25 日}
\\label{sec-5}
\\begin{frame}[label=sec-5-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電
力消費を測定するために必要なハードウェア・ソフトウェア構成を考え
る
\\begin{itemize}
\\item ハードウェアは，専用のルータではなく，一般的な PC を想定している
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-2]{研究目標}
\\begin{block}{短期的な目標 (5 月)}%x
\\begin{itemize}
\\item 中井さんが提案した NDN ルータの電力消費モデルをマルチコア CPU に対応させる
\\end{itemize}
\\end{block}
\\begin{block}{それ以降の目標}%x
\\begin{itemize}
\\item CCNx の最新 ver に対応させる
\\item FIB ・ PIT ・ CS のテーブルサイズの大きさが，電力消費にどのような
影響を与えるかを調査する
\\begin{itemize}
\\item 該当エントリの lookup に要する時間が長くなるため，テーブルサイ
ズが大きいほうが電力消費は大きくなると思われる
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-5-3]{進捗状況}
\\begin{itemize}
\\item マルチコア CPU を搭載した NDN ルータ (ソフトウェアベース) の電力消
費を測定するために必要なハードウェア・ソフトウェア構成を考えた
\\item マルチコア CPU 環境におけるクロック数の測定方法を検討した
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-4]{現在考えられる課題一覧}
\\begin{itemize}
\\item マルチスレッドに対応した NDN ソフトウェアの作成
\\begin{itemize}
\\item 特定 CPU コアへのスレッドの割り当て (おそらく下の API を用いることで可能)
\\begin{itemize}
\\item sched\\_get\\_affinity ()
\\item sched\\_set\\_affinity ()
\\item \\url{http:linuxjm.sourceforge.jp/html/LDP_man-pages/man2/sched_setaffinity.2.html}
\\end{itemize}
\\end{itemize}
\\item CPU がマルチコアの時に電力消費量を推定できるモデルの提案
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-5]{本日のミーティングで議論したいこと}
\\begin{itemize}
\\item NDN ルータのソフトウェア構成およびハードウェア構成に問題がないか
\\item 今後行っていく作業の優先順位付け
\\item 研究室紹介に使うポスターの内容
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-6]{NDN ルータのハードウェア構成}
\\begin{itemize}
\\item CPU: Intel Xeon E3-1220 (3.1GHz x 4 コア)
\\begin{itemize}
\\item ハイパースレッディングとターボブーストはとりあえず無効化する
\\end{itemize}
\\item Memory: DDR3 16GB,1600MHz
\\begin{itemize}
\\item FIB ・ PIT ・ CS のテーブルサイズについて今は考慮しないため，
Memory サイズはそれほど考慮しない
\\end{itemize}
\\item HDD: Western Digital 2TB SATA 3.5 inch \"WD2000FYYX\"
\\begin{itemize}
\\item Memory と同様であまり考慮しない
\\end{itemize}
\\item NIC: Intel 10-Gigabit Ethernet x 2
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-7]{NDN パケットフロー}
\\begin{itemize}
\\item 4 コアなので D と A0 〜 3 にそれぞれ 1 コアずつ割り当てる
\\end{itemize}
\\includegraphics[width=.9\\linewidth]{./figure/hardware.pdf}
\\end{frame}
\\begin{frame}[label=sec-5-8]{NDN ルータのソフトウェア構成の概要}
\\begin{itemize}
\\item ソフトウェアの動作は，基本的に CCNx に従う
\\begin{itemize}
\\item Cisco の NDN ルータのソフトウェアではオプションの処理ができず，
現実的に利用するのは難しいと判断したため
\\end{itemize}
\\item 一方で， PIT と CS に関しては，複数の CPU が同一エントリへアクセス
した時の排他制御によるパフォーマンスの低下が大きいと予想されるため，
PIT と CS はパーティショニングを行う
\\begin{itemize}
\\item マルチコアへのスレッドの割り当てなどは Cisco のデモを参考にする
\\end{itemize}
\\item ソフトウェアでは次のことを行う
\\begin{itemize}
\\item NDN パケットのフォワーディング処理
\\item CPU コアへのスレッドの割り当て (ディスパッチ処理)
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-9]{NDN ルータのソフトウェア}
\\begin{itemize}
\\item パケットの full-name のハッシュ値によって，パケットの処理を各 CPU コ
アに振り分ける
\\begin{itemize}
\\item NPHT (FIB ・ PIT) と CS を 3 つにパーティショニングする
\\begin{itemize}
\\item NPHT は， bucket が 6 つだとすると， 0 ・ 1 はテーブル 1 とし
てコア 1 ， 2 ・ 3 はテーブル 2 としてコア 2 ， 4 ・ 5 はテー
ブル 3 としてコア 3 というように割り当てする
\\item FIB までパーティショニングされてしまい， parent にリンクを貼
ることによる fast lookup が使えないという問題がある
\\end{itemize}
\\end{itemize}
\\item PIT (CS) の lookup 処理および insert 処理の前に，処理対象のパケッ
トの full-name をハッシュ化
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-5-10]{}
\\includegraphics[width=.9\\linewidth]{./figure/CCN_Algorithm_detail.pdf}
\\end{frame}

\\begin{frame}[label=sec-5-11]{Interest パケットがデーモンに到着した時のシーケンス}
\\begin{enumerate}
\\item パケットを name 部とオプション部に parse
\\item duplication check (重複検知)
\\item パケットの name 部からハッシュ値を計算， Prefix Seek の処理以降を
スレッドにし， ハッシュ値に応じた CPU コアに割り当て
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-5-12]{マルチコア CPU 環境におけるクロック数の測定方法}
\\begin{itemize}
\\item おそらく中井さんが用いた RDTSC 命令を用いることで，マルチコア CPU で
もクロック数の測定が可能である
\\begin{itemize}
\\item タイムスタンプカウンタ (TSC) が， Invariant TSC ならばマルチコ
ア環境でも正確にクロック数を測定可能である
\\begin{itemize}
\\item \\url{http:www.02.246.ne.jp/~torutk/cxx/clock/cpucounter.html}
\\end{itemize}
\\item 本実験で使う予定の Intel Xeon E3-1220 は Invariant TSC であることを確認した
\\end{itemize}
\\item さらに， Turbo boost でクロック数が変化した場合でも正確にクロック
を測定できる
\\item 一方で，マルチ CPU 環境ではクロック測定が困難であると予想される
\\begin{itemize}
\\item クロック数をリセットする信号がプロセッサ単位でしか送信できない
ため
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-5-13]{}
\\end{frame}

\\section{2014 年 3 月 17 日}
\\label{sec-6}
\\begin{frame}[label=sec-6-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えるかどうかを確認する
\\item 「 named data networking on a router forwarding at 20 gbps and
beyond 」を参考に， 20Gb や 40Gb の転送速度を出せるソフトウェアルー
タを作る時に，必要となるハードウェアの構成を考える
\\item CCNx のデータ構造とオペレーショナルフローについてまとめた資料の誤
りを修正する
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-2]{研究目標}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標 (5 月)}%x
\\begin{itemize}
\\item 現在，ルータのモデル化は， CPU がシングルコアの時のみできているた
め，モデルをマルチコア or マルチ CPU に対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-6-3]{目標達成に向けてのアプローチ}
\\begin{enumerate}
\\item 中井さんの資料および CCNx のソースコードを読み， CCNx ver8.1 の処理をブロッ
クに分割し，それぞれのブロックの処理に必要なクロック数を測定する
(最新 ver に拘らないならば，中井さんが実験を行った ver7.2 を使えばよ
 いため，このプロセスは飛ばすことができる)
\\item 1.で計測されたクロック数を基に， CCNx の挙動を模倣するプログラムを
作成する
\\begin{itemize}
\\item CCNx はマルチスレッドに対応していない (?) ため
\\item CCNx における各ブロックの処理にかかるクロック数だけ， dummy の処
理を行わせる
\\item NDN パケットの送受信するタイミングで， UDP パケットを送受信す
る
\\end{itemize}
\\item 2.で作成したプログラムを動作させた PC の電力消費を測定する
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-6-4]{進捗状況}
\\begin{itemize}
\\item 中井さんがクロック数を測定した PC (CPU:Intel Xeon) で，
10Gigabit-Ethernet カードが使えることを確認した
\\begin{itemize}
\\item 他の PC とケーブルで繋ぎ， ping が通ることを確認
\\item 当該 PC の 10Gigabit-Ethernet カードを接続するスロット数 (PCI-Express x8)
は 1 つで，カードのインターフェース数は 2 つのため，最大で
20Gbps までしか測定できない
\\end{itemize}
\\item 「 named data networking on a router forwarding at
20 Gbps and beyond 」を読み必要なハードウェア構成について考えた
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-5]{議論したいこと}
\\begin{itemize}
\\item 今回ハードウェアの構成を考えたが， CCNx の動作で 20Gbps を達成するのは困難である
と予想された
\\item したがって，何にフォーカスを当て (コントリビューションは何か) ，
何を優先すべきかを議論したいと考えている
\\begin{itemize}
\\item 中井さんの提案したモデルを， CCNx の最新版に対応させること
\\item 中井さんの提案したモデルを，マルチコア or マルチ CPU に対応させること
\\item 現実的なアクセスルータを考慮して， 20Gbps や 40Gbps のスループットを達成できるハードウェアと，ソフ
トウェアを調査し，その電力消費量を測定すること
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-6]{}
\\begin{itemize}
\\item 次ページより，「 named data networking on a router forwarding at
20 Gbps and beyond 」の内容をまとめる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-7]{概要}
\\begin{itemize}
\\item Cisco ASR9000 上の Linux で NDN フォワーディングエンジンを動作さ
せ，そのパフォーマンスを測定している
\\item NDN フォワーディングエンジンは CCNx ではなく， CS ・ FIB ・ PIT のデータ構造も異なっ
ている
\\item シミュレーションの結果， Interest および Data のフォワーディング
スループットが， 20Gbps を超えることを示している
\\begin{itemize}
\\item シミュレーションでは，実際には NIC を通したパケットの送受信を行っておらず，
ファイルからパケットを読み込むことで擬似的なフォワーディング処理
を行っている
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-8]{Cisco の NDN ソフトウェアルータのハードウェア構成}
\\begin{itemize}
\\item モデル名: Cisco ASR9000
\\item CPU: Intel Xeon (Westmeie-EP) 2.0GHz 6 コア (Hyper-threading 有) * 2
\\item LAN: Intel Niantic 10Gigabit Ethernet  * 4
\\item Storage: 3.2TB SSD (NDN の Cache Storage として使用)
\\item 64bit Linux 上のソフトウェアでパケットフォワーディングを行ってい
る
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-9]{NDN フォワーディングエンジン}
\\begin{itemize}
\\item CCNx とはデータ構造や look up の方法が大きく異なる
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-10]{FIB}
\\begin{itemize}
\\item FIB look up の方法が CCNx と異なる (あまり関係なさそうなので割愛)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-11]{CS ・ PIT}
\\begin{itemize}
\\item CS と PIT の管理は 1 つのハッシュテーブルで行い， look up は同時に
行う
\\begin{itemize}
\\item どちらも full-name を key とするため
\\item エントリが CS のものか PIT のものかは 1bit の flag で判断する
\\end{itemize}
\\item PIT (CS/PIT) を CPU の各コア (thread) に分割する
\\begin{itemize}
\\item 複数のコアで PIT を共有するとパフォーマンスが落ちるため
\\item Interest および Data の full-name のハッシュで PIT を CPU コア
(thread) に振り分け
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-12]{NDN パケットのフロー}
\\begin{itemize}
\\item App process (A0 〜 A7) で， NDN フォワーディング処理をすべて行う
(CS/PIT look up ， FIB look up)
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.6\\textheight]{./figure/NDN_packet_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-13]{シミュレーション結果}
\\begin{itemize}
\\item 16 個の IRCache URL のトレースから 1300 万 Interest を作成し，シミュレー
ションを行っている
\\item 異なる CPU コア上で動作させるスレッド数の増加に伴いパフォーマンスは向上している
\\item FIB と PIT のサイズはパフォーマンスにほとんど影響を与えていない
\\begin{itemize}
\\item PIT/CS サイズが向上するとパフォーマンスが低下していることから，
PIT/CS look up でほとんどヒットせず，エントリの探索に時間がかかっ
ただけになっているからではないかと思われる
\\end{itemize}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.4\\textheight]{./figure/performance_of_NDN.pdf}
\\end{frame}

\\begin{frame}[label=sec-6-14]{20Gbps を達成する時に必要な CPU}
\\begin{itemize}
\\item 29.78G (clocks/s) を達成できるもの
\\begin{itemize}
\\item 1 秒間に処理するパケット数を算出 (パケットサイズ 2KB は， Interest と Data が同
数であると仮定し，標準チャンクサイズ 4KB を 2 で割って算出
(Interest のサイズは小さいので無視))
\\begin{itemize}
\\item 20Gbps / (2K*8) = 1.25M (packet/s)
\\end{itemize}
\\item Interest と Data のペアの処理にかかる合計クロック数 48787 をかけ
て 2 で割る (こちらも Interest と Data が同数であると仮定． CS
HIT0\\%のとき．中井さんの論文から算出)
\\begin{itemize}
\\item 1.25M * 48784 / 2  = 30491.88 M (clocks/s)
= 29.78 G (clocks/s)
\\end{itemize}
\\end{itemize}
\\item 上の計算仮定には， XML の処理が入っていない．また，パケットサイズ
を 2KB としているが， Cisco は 500B としている．したがって，上記の
結果は甘く見積もっており， CCNx の挙動をそのまま模倣すると CPU の処
理が間に合わないと予想される．
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-15]{20Gbps を達成する時に必要な主記憶}
\\begin{itemize}
\\item Cisco のデモから， FIB および PIT のサイズはあまりスループットに影響し
ていないため， 1Gbyte もあれば十分ではないかと思われる
\\item 一方で， FIB ・ PIT の fast look up は時間のかかる処理であるため，
主記憶の速度は重要である
\\begin{itemize}
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-6-16]{20Gbps を達成する時に必要なネットワークインターフェース}
\\begin{itemize}
\\item 10Gigabit-Ethernet * 4
\\begin{itemize}
\\item Cisco と同様
\\item 十分考えられていない
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-6-17]{}
\\end{frame}

\\section{2014 年 3 月 12 日}
\\label{sec-7}
\\begin{frame}[label=sec-7-1]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめたが，説明不足な部分があったた
め，コメントに基づいて更新を行なう
\\item 今後どのように研究を進めていくかを本日のミーティングで検討する
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{中期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}

\\begin{frame}[label=sec-7-2]{進捗状況}
\\begin{itemize}
\\item 中井さんから，以下のことを引き継ぎしてもらった
\\begin{itemize}
\\item CCNx のソースコード中に RDTSC を埋め込んでクロック数を測定する方法
\\item 実験のネットワークへのアクセス方法と実験用スクリプトの使い方
\\end{itemize}
\\item 3/24 (月) に，実機を使って電力消費の測定を行なう (CCNx は，中井
さんが使っていたのと同じ ver7.1 を使用する)
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-3]{今後の予定 (仮)}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」と実
際のソースコードを読んだことで， CCNx の概要が分かってきたと思うた
め，ソースコードを読み進めつつ，ソースコード中のどこでクロックを
測定するべきか考えて行きたいと思っている
\\item 並行して， CCNx の理解を深めるため， CCNx1.0 へのロードマップを読み
進めていきたいと考えている (100 ページ程度あるため 2 〜 3 週間を目安に
考えている)
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-4]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-5]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-6]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-7]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-7-8]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item ver8.1 では， SHT らしきものが見つけられなかった (重要ならばもう少し時間
をかけてソースコードを読みたいと思います)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-9]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\begin{itemize}
\\item 詳細は次ページ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-10]{CSL におけるコンテンツ名順の lookup}
\\begin{itemize}
\\item CSL では， Data がコンテンツの名前順に整列されている
\\item CSL での lookup のアルゴリズム挙動は次の通り
\\begin{enumerate}
\\item 右にポインタを辿り検索対象コンテンツ名とノードを比較する．
\\begin{itemize}
\\item コンテンツ名 $<$ ノード 再び 1 へ
\\item コンテツ名 $>$ ノード 元のノードへ戻り，階層を 1 つ下げて再び
1 へ，最下層なら 2 へ
\\item コンテンツ名 = ノード マッチしたので探索終了
\\end{itemize}
\\item 探索するコンテンツが存在しないので探索終了
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.9\\linewidth,height=0.5\\textheight]{./figure/cs_skiplist.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-11]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) のエントリ
Name Prefix Entry (NPE) によって管理される
\\begin{itemize}
\\item NPE は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\begin{block}{PEs}%x
\\begin{itemize}
\\item エントリ同士は，双方向でリンクされている
\\item メンバ変数
\\begin{itemize}
\\item 元の interest (unsigned int 型なので，おそらくバイナリのまま．
コメントによるとマッチングに使用する)
\\item 転送した interest のメッセージとそのサイズ
\\end{itemize}
\\end{itemize}
\\end{block}
\\begin{block}{FIEs}%x
\\begin{itemize}
\\item NPE 中に存在
\\item メンバ変数
\\begin{itemize}
\\item face の id
\\item expire までの残り時間
\\end{itemize}
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-7-12]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\begin{itemize}
\\item Interest: process\\_incoming\\_interest
\\item Data: process\\_incoming\\_content
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-13]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-14]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の nameprefix が\\alert{すべて}存在するかを NPHT で
チェックする (Interest が/a/b/0/1 ならば，/a ・/a/b ・/a/b/0 ・
/a/b/0/1 をすべて)
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため挿入されたエントリは親 (1 コンポ
ネント短いエントリ) へのポインタを張る (Data が daemon に到
着した際に，できるだけ多くの Interest を消費するため． (3)
で詳細を述べる)
\\end{enumerate}
\\end{enumerate}
\\end{itemize}
\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-15]{Interest 処理のオペレーショナルフロー (2)}
\\begin{itemize}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\begin{itemize}
\\item コンポーネント数の比較
\\item Name 全体の長さの比較
\\item memcmp における Binary の Name 自体の比較
\\end{itemize}
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する Exclude や
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-16]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後，
Data を返送し， NPHT と PHT から Interest を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，/a/b/0/1 ・/a/b/0 ・/a/b ・/a を探索する
\\begin{itemize}
\\item オプションによっては， Interest の fullname と NPHT のエント
リが完全一致しなくても良い場合があるため
\\item Interest には， MinSuffixComponents と MaxSuffixComponents というオプ
ションが存在し，マッチしてほしいコンポーネントの範囲を指定することができる
\\item 例えば， Interest の fullname が/a/b/0/1 ， MaxSuffixComponents が
3 の時， Data /a/b/0/1 でも Interest の要件を満たしている
きる
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-7-17]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-7-18]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-7-19]{よく分からなかった点}
\\begin{itemize}
\\item CCNx のデータ構造の中に「 ccn\\_forwarding 」と「 ccn\\_forwarding\\_entry 」
の 2 つのデータ構造があった
\\item この 2 つのデータ構造は，互いに関係がない
\\item NPE からリンクが貼られていたのは前者
\\end{itemize}
\\end{frame}

\\section{2014 年 3 月 5 日}
\\label{sec-8}
\\begin{frame}[label=sec-8-1]{}
\\end{frame}
\\begin{frame}[label=sec-8-2]{前回ミーティングのまとめ}
\\begin{itemize}
\\item 「 Scalable NDN Forwarding:Concepts, Issues and Principles 」を読
み， CCNx のデータ構造についてまとめ， CCNx のデータ構造について
の理解を深める
\\end{itemize}
\\begin{block}{短期的な目標}%x
\\begin{itemize}
\\item CCNx の ver8.1 で機能ごとのブロックを作り，ブロックの処理に必要な
クロック数を測定する
\\end{itemize}
\\end{block}
\\begin{block}{長期的な目標}%x
\\begin{itemize}
\\item 現在はルータの CPU がシングルコアの時のみモデル化できているため，
マルチコアに対応させる
\\end{itemize}
\\end{block}
\\end{frame}
\\begin{frame}[label=sec-8-3]{Scalable NDN Forwarding:Concepts, Issues and Principles}
\\begin{itemize}
\\item 本論文は， CCNx のデータ構造とオペレーショナルフローについてまとめている
\\item ただし， CCNx の ver4.0 を対象としているため，現在の最新である
ver8.1 とは一部異なる可能性がある
\\begin{itemize}
\\item 次スライドから述べる CCNx のデータ構造は ver4.0 のものであること
に留意する
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-4]{CCNx のデータ構造}
\\begin{itemize}
\\item CCNx のデータ構造は NDN と異なっている
\\begin{itemize}
\\item NDN
\\begin{itemize}
\\item CS ・ FIB ・ PIT の 3 つのテーブルを持つ
\\end{itemize}
\\item CCNx
\\begin{itemize}
\\item CS に相当する Content Hash Table (CHT) と Content Skip List
(CSL) を持つ
\\item FIB と PIT に相当する Name Prefix Hash Table (NPHT) を持つ
\\item PIT に存在するすべての Interest (PEs の形) の nonce を保持す
る Propagating Hash Table (PHT) を持つ
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-5]{CCNx のデータ構造図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_structure.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-6]{CCNx における CS の概要}
\\begin{itemize}
\\item Data の格納場所と， Data を指すポインタをエントリに持つテーブルに分けられる
\\begin{itemize}
\\item Data の格納場所
\\begin{itemize}
\\item Content Array (CA)
\\item Straggler Hash Table (SHT)
\\end{itemize}
\\item テーブル
\\begin{itemize}
\\item Content Hash Table (CHT)
\\item Content Skip List (CSL)
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-7]{CS における Data の格納}
\\begin{itemize}
\\item Data に番号をつけて， CA か SHT に保存する
\\begin{itemize}
\\item daemon に到着した Data には，ユニークな accession number が割り
当てられる
\\begin{itemize}
\\item accession number は， 1 ずつ増加する
\\end{itemize}
\\item キャッシュされた Data は， Content Array (CA) に保存さ
れ， accession number によってインデックスされる
\\item Data がキャッシュされるごとに CA がサポートする accession
number の範囲が移動する
\\begin{itemize}
\\item サポートするスロット数は固定であるため，スライディングウィン
ドウのようにサポートする場所が移動していく
\\end{itemize}
\\item 古くなり CA のサポートから外れたが，人気のある Data は， SHT に
保存される
\\begin{itemize}
\\item どうやって Data が人気か判断するのか， CA と同じように accession
number でアクセスするのか分からないため，ソースを読む必要があ
る
\\end{itemize}
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-8]{Content Store のテーブル}
\\begin{itemize}
\\item Content Hash Table (CHT)
\\begin{itemize}
\\item key は Data のフルネーム
\\end{itemize}
\\item Content Skip List (CSL)
\\begin{itemize}
\\item 標準的な skip list
\\item コンテンツ名順の lookup をサポートするために必要
\\end{itemize}
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-9]{CCNx における FIB と PIT の概要}
\\begin{itemize}
\\item FIB と PIT はともに， Name Prefix Hash Table (NPHT) によって管理
される
\\begin{itemize}
\\item NPHT は Propagating Entries (PEs) と Forwarding Info Entries
(FIEs) にインデックスしている
\\end{itemize}
\\end{itemize}
\\end{frame}


\\begin{frame}[label=sec-8-10]{CCNx のオペレーショナルフロー}
\\begin{itemize}
\\item CCNx では， Interest と Data は，異なる関数で処理される
\\end{itemize}
\\end{frame}

\\begin{frame}[label=sec-8-11]{Interest 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_interest_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-12]{Interest 処理のオペレーショナルフロー (1)}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， name 部とオプション部に
parse
\\item Interest の nonce を key として， PHT で正確な一致検索を行う
\\begin{itemize}
\\item loop している Interest の破棄
\\end{itemize}
\\item Prefix Seek を行う
\\begin{enumerate}
\\item Interest の prefix が\\alert{すべて}存在するかを NPHT でチェックする
\\item 存在しなければ， NPHT に新たなエントリを作成
\\item 2 の時， fast lookup のため prefix は親へのポインタを張る
\\end{enumerate}
\\end{enumerate}
\\end{itemize}

\\includegraphics[width=0.8\\linewidth,height=0.15\\paperheight]{./figure/npht.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-13]{Interest 処理のオペレーショナルフロー (2)}
\\begin{enumerate}
\\item Interest に対応する Data がキャッシュされているか CS をチェック
\\begin{enumerate}
\\item CSL で潜在的にマッチし得るコンテンツを探索
\\item マッチした場合，そのコンテンツを CS から取ってきて，本当に
Interest を満たすものかどうかチェック
\\begin{itemize}
\\item Interest には，特定コンテンツを排除する除外フィルタなどがあ
るため name だけでは不十分であるため
\\end{itemize}
\\end{enumerate}
\\end{enumerate}
\\end{frame}
\\begin{frame}[label=sec-8-14]{Interest 処理のオペレーショナルフロー (3)}
\\begin{enumerate}
\\item コンテンツ有: Interest を消費した (Interest Comsuming の処理) 後， Data パケットを返送し， NPHT
と PHT から Interest の name を除去
\\begin{itemize}
\\item Data が/a/b/0/1 なら，\\alert{/a/b/0 ・/a/b ・/a をすべて}探索
する
\\begin{itemize}
\\item できるだけ多くの Interest を消費するため
\\item 例えば， Interest /a/b/0 が，最初の 3 コンポネントでのみのマッチを
必要としている場合，コンテンツ/a/b/0/1 が Interest/a/b/0 を満たす
\\end{itemize}
\\end{itemize}

\\item コンテンツ無: NPHT で最長一致検索を行う (FIB の処理)
\\begin{enumerate}
\\item Interest の fullname で探索→ 1 つコンポネント長を短くしたもの
で探索．．．．．．をマッチするか， root prefix に到達するまで繰り返す
\\item Interest を転送した後， NPHT に Interest message を含んだエントリ
を追加， PHT に Interest の nonce を追加
\\end{enumerate}
\\end{enumerate}
\\end{frame}

\\begin{frame}[label=sec-8-15]{Data 処理のオペレーショナルフロー図}
\\includegraphics[width=.9\\linewidth]{./figure/ccnx_data_flow.pdf}
\\end{frame}

\\begin{frame}[label=sec-8-16]{Data 処理のオペレーショナルフロー}
\\begin{itemize}
\\item Interest が CCNx daemon に到着した時の処理を順に述べる
\\begin{enumerate}
\\item CCNx daemon は，バイナリをデコードし， parse
\\item CS seek, saving
\\begin{itemize}
\\item CHT での正確なマッチングを行い，キャシュされているかを確認
(key は Data の full name)
\\item Data は， CHT と CSL に挿入され， CS に格納される
\\end{itemize}
\\item Interest の処理と同様の Interest Consuming の処理
\\end{enumerate}
\\end{itemize}
\\end{frame}
\\begin{frame}[label=sec-8-17]{所感}
\\begin{itemize}
\\item CCNx のデータ構造について大まかな理解はできたと思われる
\\item 一方で，各テーブルのエントリの構造などの細かい所については触れられ
ていなかったため，ソースコードを読んでいく必要があると感じた
\\end{itemize}
\\end{frame}
% Emacs 24.3.1 (Org mode 8.2.5h)
\\end{document}" #("
" 0 1 (fontified t)) #("   - 
     - " 0 5 (fontified t) 5 6 (fontified t) 6 13 (fontified t))))
(setq-default session-file-alist '(("/mnt/Dropbox/meeting/withHasegawa/GreenICN/M2-meeting.org" 612 662 1 nil nil 614 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/varying_ncpu/dispatcher_pseudocode.c" 461 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/varying_ncpu/main_pseudocode.c" 1 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/varying_ncpu/select_cpu_pseudocode.c" 1 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/varying_ncpu/process_incoming_message_pseudocode.c" 174 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/varying_ncpu/packet_process_pseudocode.c" 1 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/var/recentf" 11026 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/M2-meeting.tex" 39758 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/process_incoming_message_pseudocode.c" 329 635 1 nil nil 595 (overwrite-mode)) ("/ssh:k-ohsugi@133.1.244.3:/var/www/html/member.html" 10658 10267 1 nil nil 10569 (overwrite-mode)) ("/ssh:k-ohsugi@133.1.244.3:/var/www/html/member_e.html" 10229 9973 1 nil nil 10229 (overwrite-mode)) ("~/Dropbox/configure/.emacs.d/var/recentf" 11008 nil 1 nil nil nil (overwrite-mode)) ("~/hsgw-lab_namelist.xlsx" 1 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/main_pseudocode.c" 706 427 1 nil nil 692 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/dispatcher_pseudocode.c" 32 32 1 nil nil 32 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/select_cpu_pseudocode.c" 320 1 1 nil nil 320 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/packet_process_pseudocode.c" 621 621 1 nil nil 621 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/storage/dispatcher_pseudocode.txt" 42 nil 1 nil nil 26 (overwrite-mode)) ("~/.config/awesome/wi.lua" 346 1392 1 nil nil nil (overwrite-mode)) ("~/.config/awesome/rc.lua" 2408 14501 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/act.org" 1 nil 1 nil nil 56 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/url/cookies" 505 nil 1 nil nil nil (overwrite-mode)) ("~/.config/awesome/themes/dust/theme.lua" 788 746 1 nil nil 788 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/auto-complete-20140414.2324/auto-complete-autoloads.el" 1481 nil 1 nil nil 1481 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/helm-20140414.2313/helm-autoloads.el" 45694 nil 1 nil nil 45694 (overwrite-mode)) ("~/Dropbox/meeting/withHasegawa/GreenICN/M2-meeting.org" 641 nil 1 nil nil nil (overwrite-mode)) ("~/Dropbox/configure/.emacs.d/url/cookies" 505 nil 1 nil nil nil (overwrite-mode)) ("~/Dropbox/configure/.emacs.d/elpa/lua-mode-20140413.840/lua-mode-autoloads.el" 512 nil 1 nil nil 512 (overwrite-mode)) ("/mnt/Dropbox/lab/graduate_school_entrance_examination.org" 1518 1441 1 nil nil 1517 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/inits/20_org-mode.el" 850 891 1 nil nil 850 (overwrite-mode)) ("/mnt/Dropbox/lab/graduate_school_entrance_examination.tex" 2329 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/research/receive.c" 697 381 1 nil nil 697 (overwrite-mode)) ("/mnt/Dropbox/research/send.c" 5290 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/research/forwarding.c" 999 510 1 nil nil 1152 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/helm-20140411.536/helm-autoloads.el" 45695 nil 1 nil nil 45695 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/lua-mode-20140411.707/lua-mode-autoloads.el" 511 nil 1 nil nil 511 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/helm-20140409.2254/helm-autoloads.el" 45692 nil 1 nil nil 45692 (overwrite-mode)) ("/mnt/Dropbox/scfes.org" 306 nil 1 nil nil 361 (overwrite-mode)) ("/mnt/Dropbox/meeting/withHasegawa/GreenICN/ohsugi-M1-meeting.org" 169 nil 1 nil nil nil (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/snippets/org-mode/report" 50 nil 1 nil nil 67 (overwrite-mode)) ("/mnt/Dropbox/configure/.emacs.d/elpa/color-theme-solarized-20140408.1309/color-theme-solarized-autoloads.el" 1190 nil 1 nil nil 1190 (overwrite-mode)) ("~/LoveLive!/\342-'s Best Album Best Live! collection [Di/2-13 Daring!!.mp3" 1 nil 1 nil nil nil (overwrite-mode)) ("~/Dropbox/meeting/withHasegawa/GreenICN/ohsugi-M1-meeting.org" 1195 1083 1 nil nil 1195 (overwrite-mode)) ("~/Dropbox/meeting/withHasegawa/GreenICN/ohsugi-M1-meeting.tex" 31638 nil 1 nil nil nil (overwrite-mode))))
(setq-default TeX-command-history '("LatexMk" "Clean All" "Evince"))
(setq-default buffer-name-history '("*Packages*" "*Macroexpansion*" "*Org PDF LaTeX Output*" "2-13 Daring!!.mp3" "*Backtrace*" "20_org-mode.el" "hote.txt" "es.org" "PKGBUILD" "*init log*"))
(setq-default coding-system-history '("shift_jis" "utf-8-unix" "unix"))
(setq-default command-history '((find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/process_incoming_message_pseudocode.c" t) (find-file "/ssh:k-ohsugi@133.1.244.3:/var/www/html/member_e.html" t) (find-file "/ssh:k-ohsugi@133.1.244.3:/var/www/html/member.html" t) (find-file "/ssh:k-ohsugi@133.1.244.3:~/" t) (find-file "/ssh:k-oshugi@133.1.244.3:~/" t) (find-file "/ssh:k-oshugi@133.1.244.3" t) (find-file "/mnt/anime/東のエデン/" t) (find-file "~/Dropbox/act.org" t) (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/select_cpu_pseudocode.c" t) (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/main_pseudocode.c" t) (find-file "~/Dropbox/configure/.emacs.d/inits/" t) (find-file "~/Dropbox/configure/.emacs.d/" t) (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/packet_process_pseudocode.c" t) (kill-buffer "*Packages*") (kill-buffer "*Macroexpansion*") (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/dispatcher_pseudocode.c" t) (find-file "~/.config/awesome/themes/dust/theme.lua" t) (find-file "~/.config/awesome/themes/" t) (find-file "~/.config/awesome/wi.lua" t) (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/storage/dispatcher_pseudocode.txt" t) (find-file "~/Dropbox/hoge/\353@\304\304\342t\342H\342\357\342_/By Imase Lab/" t) (find-file "~/Dropbox/hoge/" t) (kill-buffer "*Org PDF LaTeX Output*") (find-file "~/Dropbox/meeting/withHasegawa/GreenICN/M2-meeting.org" t) (find-file "~/Dropbox/research/forwarding.c" t) (yas-load-snippet-buffer-and-close (quote org-mode) nil) (find-file "~/Dropbox/lab/graduate_school_entrance_examination.tex" t) (find-file "~/Dropbox/lab/graduate_school_entrance_examination.org" t) (find-file "~/Dropbox/lab/graduate school entrance examination.org" t) (dired-create-directory "~/Dropbox/lab") (find-file "~/Dropbox/" t) (find-file "~/LoveLive!/\342-'s Best Album Best Live! collection [Di/" t) (set-buffer-file-coding-system (quote utf-8-unix) nil) (set-buffer-file-coding-system (quote unix) nil) (kill-buffer "2-13 Daring!!.mp3")))
(setq-default extended-command-history '("package-list-packages" "eval-buffer" "count-lines-region" "describe-variable" "describe-function" "auto-complete-mode" "describe-mode" "Buffer-menu-mode" "describe-key" "eval-defun" "pascal-mode"))
(setq-default helm-c-grep-history '("valid-file" "filename"))
(setq-default helm-c-source-complex-command-history '((name . "Complex Command History") (candidates lambda nil (mapcar (quote prin1-to-string) command-history)) (type . sexp)))
(setq-default helm-c-source-file-name-history '((name . "File Name History") (candidates . file-name-history) (persistent-action . ignore) (filtered-candidate-transformer . helm-file-name-history-transformer) (action ("Find file" . helm-find-many-files) ("Find file as root" . helm-find-file-as-root) ("Find file other window" . find-file-other-window) ("Find file other frame" . find-file-other-frame) ("Open dired in file's directory" . helm-open-dired) ("Grep File(s) `C-u recurse'" . helm-find-files-grep) ("Zgrep File(s) `C-u Recurse'" . helm-ff-zgrep) ("Pdfgrep File(s)" . helm-ff-pdfgrep) ("Insert as org link" . helm-files-insert-as-org-link) ("Checksum File" . helm-ff-checksum) ("Ediff File" . helm-find-files-ediff-files) ("Ediff Merge File" . helm-find-files-ediff-merge-files) ("Etags `M-., C-u tap, C-u C-u reload tag file'" . helm-ff-etags-select) ("View file" . view-file) ("Insert file" . insert-file) ("Delete file(s)" . helm-delete-marked-files) ("Open file externally (C-u to choose)" . helm-open-file-externally) ("Open file with default tool" . helm-open-file-with-default-tool) ("Find file in hex dump" . hexl-find-file))))
(setq-default helm-c-source-global-mark-ring '((name . "global-mark-ring") (candidates . helm-global-mark-ring-get-candidates) (action ("Goto line" lambda (candidate) (let ((items (split-string candidate ":"))) (helm-switch-to-buffer (cl-second items)) (helm-goto-line (string-to-number (car items)))))) (persistent-action lambda (candidate) (let ((items (split-string candidate ":"))) (helm-switch-to-buffer (cl-second items)) (helm-goto-line (string-to-number (car items))) (helm-highlight-current-line))) (persistent-help . "Show this line")))
(setq-default helm-c-source-kill-ring '((name . "Kill Ring") (init lambda nil (helm-attrset (quote last-command) last-command)) (candidates . helm-kill-ring-candidates) (filtered-candidate-transformer helm-kill-ring-transformer) (action ("Yank" . helm-kill-ring-action) ("Delete" lambda (candidate) (cl-loop for cand in (helm-marked-candidates) do (setq kill-ring (delete cand kill-ring))))) (keymap keymap (27 keymap (117 . helm-previous-line) (121 . helm-next-line)) keymap (menu-bar keymap (help-menu keymap (describe keymap (describe-mode . helm-help)))) (help keymap (109 . helm-help)) (f1 keymap (109 . helm-help)) (8 . delete-backward-char) (20 . helm-toggle-resplit-and-swap-windows) (C-tab . undefined) (triple-mouse-3 . ignore) (double-mouse-3 . ignore) (mouse-3 . ignore) (drag-mouse-3 . ignore) (down-mouse-3 . ignore) (triple-mouse-2 . ignore) (double-mouse-2 . ignore) (mouse-2 . ignore) (drag-mouse-2 . ignore) (down-mouse-2 . ignore) (triple-mouse-1 . ignore) (double-mouse-1 . ignore) (mouse-1 . ignore) (drag-mouse-1 . ignore) (down-mouse-1 . ignore) (67108897 . helm-toggle-suspend-update) (3 keymap (1 . all-from-helm-occur) (21 . helm-force-update) (6 . helm-follow-mode) (11 . helm-kill-selection-and-quit) (25 . helm-yank-selection) (4 . helm-delete-current-selection) (45 . helm-swap-windows)) (67108987 . helm-enlarge-window) (67108989 . helm-narrow-window) (19 . undefined) (18 . undefined) (23 . helm-yank-text-at-point) (24 keymap (2 . helm-resume-list-buffers-after-quit) (98 . helm-resume-previous-session-after-quit) (6 . helm-quit-and-find-file)) (11 . helm-delete-minibuffer-contents) (67108896 . helm-toggle-visible-mark) (0 . helm-toggle-visible-mark) (C-M-up . helm-scroll-other-window-down) (C-M-down . helm-scroll-other-window) (M-prior . helm-scroll-other-window-down) (M-next . helm-scroll-other-window) (12 . helm-recenter-top-bottom-other-window) (15 . helm-next-source) (10 . helm-select-3rd-action) (5 . helm-select-2nd-action-or-end-of-line) (26 . helm-execute-persistent-action) (9 . helm-select-action) (13 . helm-exit-minibuffer) (left . helm-previous-source) (right . helm-next-source) (7 . helm-keyboard-quit) (22 . helm-next-page) (27 keymap (110 . next-history-element) (112 . previous-history-element) (115 . undefined) (5 . helm-display-all-sources) (1 . helm-show-all-in-this-source-only) (117 . helm-unmark-all) (97 . helm-mark-all) (109 . helm-toggle-all-marks) (41 . helm-next-visible-mark) (40 . helm-prev-visible-mark) (91) (32 . helm-toggle-visible-mark) (33554454 . helm-scroll-other-window-down) (25 . helm-scroll-other-window-down) (22 . helm-scroll-other-window) (12 . helm-reposition-window-other-window) (62 . helm-end-of-buffer) (60 . helm-beginning-of-buffer) (118 . helm-previous-page)) (next . helm-next-page) (prior . helm-previous-page) (16 . helm-previous-line) (14 . helm-next-line) (up . helm-previous-line) (down . helm-next-line) keymap (26 . undefined) (18 . helm-minibuffer-history) (S-tab . zlc-select-previous) (backtab . zlc-select-previous) (menu-bar keymap (minibuf #1="Minibuf" keymap (previous menu-item "Previous History Item" previous-history-element :help "Put previous minibuffer history element in the minibuffer") (next menu-item "Next History Item" next-history-element :help "Put next minibuffer history element in the minibuffer") (isearch-backward menu-item "Isearch History Backward" isearch-backward :help "Incrementally search minibuffer history backward") (isearch-forward menu-item "Isearch History Forward" isearch-forward :help "Incrementally search minibuffer history forward") (return menu-item "Enter" exit-minibuffer :key-sequence "" :help "Terminate input and exit minibuffer") (quit menu-item "Quit" abort-recursive-edit :help "Abort input and exit minibuffer") #1#)) (10 . exit-minibuffer) (13 . exit-minibuffer) (7 . minibuffer-keyboard-quit) (C-tab . file-cache-minibuffer-complete) (9 . self-insert-command) (XF86Back . previous-history-element) (up . previous-history-element) (prior . previous-history-element) (XF86Forward . next-history-element) (down . next-history-element) (next . next-history-element) (27 keymap (63 . session-minibuffer-history-help) (114 . previous-matching-history-element) (115 . next-matching-history-element) (112 . previous-history-element) (110 . next-history-element))) (last-command . kill-region) (migemo) (multiline)))
(setq-default helm-c-source-mark-ring '((name . "mark-ring") (candidates . helm-mark-ring-get-candidates) (action ("Goto line" lambda (candidate) (helm-goto-line (string-to-number candidate)))) (persistent-action lambda (candidate) (helm-goto-line (string-to-number candidate)) (helm-highlight-current-line)) (persistent-help . "Show this line")))
(setq-default helm-grep-history '("valid-file" "filename"))
(setq-default helm-source--ff-file-name-history '((name . "File name history") (init lambda nil (with-helm-alive-p (when helm-ff-file-name-history-use-recentf (require (quote recentf)) (or recentf-mode (recentf-mode 1))))) (candidates lambda nil (if helm-ff-file-name-history-use-recentf recentf-list file-name-history)) (persistent-action . ignore) (filtered-candidate-transformer . helm-file-name-history-transformer) (action ("Find file" lambda (candidate) (helm-set-pattern (expand-file-name candidate)) (with-helm-after-update-hook (helm-exit-minibuffer))) ("Find file in helm" lambda (candidate) (helm-set-pattern (expand-file-name candidate))))))
(setq-default helm-source-complex-command-history '((name . "Complex Command History") (candidates lambda nil (mapcar (quote prin1-to-string) command-history)) (type . sexp)))
(setq-default helm-source-file-name-history '((name . "File Name History") (candidates . file-name-history) (persistent-action . ignore) (filtered-candidate-transformer . helm-file-name-history-transformer) (action ("Find file" . helm-find-many-files) ("Find file as root" . helm-find-file-as-root) ("Find file other window" . find-file-other-window) ("Find file other frame" . find-file-other-frame) ("Open dired in file's directory" . helm-open-dired) ("Grep File(s) `C-u recurse'" . helm-find-files-grep) ("Zgrep File(s) `C-u Recurse'" . helm-ff-zgrep) ("Pdfgrep File(s)" . helm-ff-pdfgrep) ("Insert as org link" . helm-files-insert-as-org-link) ("Checksum File" . helm-ff-checksum) ("Ediff File" . helm-find-files-ediff-files) ("Ediff Merge File" . helm-find-files-ediff-merge-files) ("Etags `M-., C-u tap, C-u C-u reload tag file'" . helm-ff-etags-select) ("View file" . view-file) ("Insert file" . insert-file) ("Delete file(s)" . helm-delete-marked-files) ("Open file externally (C-u to choose)" . helm-open-file-externally) ("Open file with default tool" . helm-open-file-with-default-tool) ("Find file in hex dump" . hexl-find-file))))
(setq-default helm-source-global-mark-ring '((name . "global-mark-ring") (candidates . helm-global-mark-ring-get-candidates) (action ("Goto line" lambda (candidate) (let ((items (split-string candidate ":"))) (helm-switch-to-buffer (cl-second items)) (helm-goto-line (string-to-number (car items)))))) (persistent-action lambda (candidate) (let ((items (split-string candidate ":"))) (helm-switch-to-buffer (cl-second items)) (helm-goto-line (string-to-number (car items))) (helm-highlight-current-line))) (persistent-help . "Show this line")))
(setq-default helm-source-kill-ring '((name . "Kill Ring") (init lambda nil (helm-attrset (quote last-command) last-command)) (candidates . helm-kill-ring-candidates) (filtered-candidate-transformer helm-kill-ring-transformer) (action ("Yank" . helm-kill-ring-action) ("Delete" lambda (candidate) (cl-loop for cand in (helm-marked-candidates) do (setq kill-ring (delete cand kill-ring))))) (keymap keymap (27 keymap (117 . helm-previous-line) (121 . helm-next-line)) keymap (menu-bar keymap (help-menu keymap (describe keymap (describe-mode . helm-help)))) (help keymap (109 . helm-help)) (f1 keymap (109 . helm-help)) (8 . delete-backward-char) (20 . helm-toggle-resplit-and-swap-windows) (C-tab . undefined) (triple-mouse-3 . ignore) (double-mouse-3 . ignore) (mouse-3 . ignore) (drag-mouse-3 . ignore) (down-mouse-3 . ignore) (triple-mouse-2 . ignore) (double-mouse-2 . ignore) (mouse-2 . ignore) (drag-mouse-2 . ignore) (down-mouse-2 . ignore) (triple-mouse-1 . ignore) (double-mouse-1 . ignore) (mouse-1 . ignore) (drag-mouse-1 . ignore) (down-mouse-1 . ignore) (67108897 . helm-toggle-suspend-update) (3 keymap (1 . all-from-helm-occur) (21 . helm-force-update) (6 . helm-follow-mode) (11 . helm-kill-selection-and-quit) (25 . helm-yank-selection) (4 . helm-delete-current-selection) (45 . helm-swap-windows)) (67108987 . helm-enlarge-window) (67108989 . helm-narrow-window) (19 . undefined) (18 . undefined) (23 . helm-yank-text-at-point) (24 keymap (2 . helm-resume-list-buffers-after-quit) (98 . helm-resume-previous-session-after-quit) (6 . helm-quit-and-find-file)) (11 . helm-delete-minibuffer-contents) (67108896 . helm-toggle-visible-mark) (0 . helm-toggle-visible-mark) (C-M-up . helm-scroll-other-window-down) (C-M-down . helm-scroll-other-window) (M-prior . helm-scroll-other-window-down) (M-next . helm-scroll-other-window) (12 . helm-recenter-top-bottom-other-window) (15 . helm-next-source) (10 . helm-select-3rd-action) (5 . helm-select-2nd-action-or-end-of-line) (26 . helm-execute-persistent-action) (9 . helm-select-action) (13 . helm-exit-minibuffer) (left . helm-previous-source) (right . helm-next-source) (7 . helm-keyboard-quit) (22 . helm-next-page) (27 keymap (110 . next-history-element) (112 . previous-history-element) (115 . undefined) (5 . helm-display-all-sources) (1 . helm-show-all-in-this-source-only) (117 . helm-unmark-all) (97 . helm-mark-all) (109 . helm-toggle-all-marks) (41 . helm-next-visible-mark) (40 . helm-prev-visible-mark) (91) (32 . helm-toggle-visible-mark) (33554454 . helm-scroll-other-window-down) (25 . helm-scroll-other-window-down) (22 . helm-scroll-other-window) (12 . helm-reposition-window-other-window) (62 . helm-end-of-buffer) (60 . helm-beginning-of-buffer) (118 . helm-previous-page)) (next . helm-next-page) (prior . helm-previous-page) (16 . helm-previous-line) (14 . helm-next-line) (up . helm-previous-line) (down . helm-next-line) keymap (26 . undefined) (18 . helm-minibuffer-history) (S-tab . zlc-select-previous) (backtab . zlc-select-previous) (menu-bar keymap (minibuf #1="Minibuf" keymap (previous menu-item "Previous History Item" previous-history-element :help "Put previous minibuffer history element in the minibuffer") (next menu-item "Next History Item" next-history-element :help "Put next minibuffer history element in the minibuffer") (isearch-backward menu-item "Isearch History Backward" isearch-backward :help "Incrementally search minibuffer history backward") (isearch-forward menu-item "Isearch History Forward" isearch-forward :help "Incrementally search minibuffer history forward") (return menu-item "Enter" exit-minibuffer :key-sequence "" :help "Terminate input and exit minibuffer") (quit menu-item "Quit" abort-recursive-edit :help "Abort input and exit minibuffer") #1#)) (10 . exit-minibuffer) (13 . exit-minibuffer) (7 . minibuffer-keyboard-quit) (C-tab . file-cache-minibuffer-complete) (9 . self-insert-command) (XF86Back . previous-history-element) (up . previous-history-element) (prior . previous-history-element) (XF86Forward . next-history-element) (down . next-history-element) (next . next-history-element) (27 keymap (63 . session-minibuffer-history-help) (114 . previous-matching-history-element) (115 . next-matching-history-element) (112 . previous-history-element) (110 . next-history-element))) (last-command . kill-region) (migemo) (multiline)))
(setq-default helm-source-mark-ring '((name . "mark-ring") (candidates . helm-mark-ring-get-candidates) (action ("Goto line" lambda (candidate) (helm-goto-line (string-to-number candidate)))) (persistent-action lambda (candidate) (helm-goto-line (string-to-number candidate)) (helm-highlight-current-line)) (persistent-help . "Show this line")))
(setq-default minibuffer-history '("m2" "main" ".c" "select" "-------" "pack" #("bg_focus" 0 8 (fontified t)) "rc.lua" "dispatcher_pseudocode.txt" "org" "or" "eval" "eva" "targets" "tex" #("大杉" 0 2 (fontified t face (font-lock-type-face))) "org " "Latexmk" #("必須問題と選択問題がある．選択問題でネットワークを選ぶと漏れなくおまけ" 0 35 (fontified t)) "org 20" #("も対処できるかも．自分の時は，情報論" 0 8 (fontified t) 8 14 (fontified t) 14 18 (fontified t)) "rec" "send" "pa" "org-mode" "report" "evince graduate_school_entrance_examination.pdf" #("
" 0 1 (fontified t)) #("2-15" 0 4 (dired-filename t mouse-face highlight help-echo "mouse-2: visit this file in other window" fontified t)) #("./pdf/" 0 1 (face font-lock-string-face fontified t) 1 2 (face font-lock-string-face fontified t) 2 3 (face font-lock-string-face fontified t) 3 4 (face font-lock-string-face fontified t) 4 5 (face font-lock-string-face fontified t) 5 6 (face font-lock-string-face fontified t)) "figure" "rc" "rc." "evince hoge.pdf" "hoge" "hoge.bib" "auto-com" "zshrc" "p" "fu" "future" #("centering" 0 9 (fontified t)) "hitachi"))
(setq-default occur-collect-regexp-history '("\\1"))
(setq-default query-replace-history '("research_2014_group_001-ccn.pdf" "research_group_001-icn.pdf" "M1" "B4" "M" "M2" "Master" "Doctor" "D3" "./figure/" "./"))
(setq-default search-ring '("\")" "wall" " " "pdf" "urata" "watabe" "hujita" "org-" "mein" "correct" "orgdef" "org" "auto-co" "ac " "auto-complete" "company"))
(setq-default serial-name-history '("/dev/ttyS0"))
(setq-default serial-speed-history '("9600" "1200" "2400" "4800" "14400" "19200" "28800" "38400" "57600" "115200"))
(setq-default table-capture-columns-history '(""))
(setq-default table-capture-justify-history '("left"))
(setq-default table-capture-min-cell-width-history '("5"))
(setq-default table-cell-height-history '("1"))
(setq-default table-cell-span-direction-history '("right"))
(setq-default table-cell-split-contents-to-history '("split"))
(setq-default table-cell-split-orientation-history '("horizontally"))
(setq-default table-cell-width-history '("5"))
(setq-default table-col-delim-regexp-history '(""))
(setq-default table-columns-history '("3"))
(setq-default table-insert-row-column-history '("row"))
(setq-default table-justify-history '("center"))
(setq-default table-row-delim-regexp-history '(""))
(setq-default table-rows-history '("3"))
(setq-default table-sequence-count-history '("0"))
(setq-default table-sequence-increment-history '("1"))
(setq-default table-sequence-interval-history '("1"))
(setq-default table-sequence-justify-history '("left"))
(setq-default table-sequence-string-history '("0"))
(setq-default table-source-caption-history '("Table"))
(setq-default table-source-language-history '("html"))
(setq-default table-target-history '("cell"))
